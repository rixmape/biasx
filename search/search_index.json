{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to BiasX BiasX is a Python library designed for the comprehensive analysis of gender bias in face classification models. It provides a pipeline to evaluate model performance, generate visual explanations for model decisions, and calculate quantitative bias metrics. Understanding and mitigating bias in AI models is crucial, especially in sensitive applications like facial recognition. BiasX aims to provide researchers and developers with the tools needed to identify how and why their models might exhibit different behaviors across demographic groups. Key Features Model Loading & Inference: Handles loading TensorFlow/Keras models and running predictions. Dataset Management: Loads and preprocesses standard facial image datasets like UTKFace and FairFace. Visual Explanations: Generates Class Activation Maps (CAMs) using methods like GradCAM, GradCAM++, and ScoreCAM to highlight regions influencing predictions. Detects facial landmarks (eyes, nose, mouth, etc.) using providers like MediaPipe. Bias Calculation: Analyzes the correlation between activated facial features and misclassifications across genders. Calculates overall bias disparity scores, including Equalized Odds. Configurable Pipeline: Allows easy configuration of datasets, models, explanation methods, and analysis parameters through YAML files or Python dictionaries. Getting Started New to BiasX? Start with the Getting Started guide to walk through a basic analysis example. Check the Installation guide for setup instructions. Explore the Configuration options to customize the analysis pipeline. Dive deep into the components with the API Reference .","title":"Home"},{"location":"#welcome-to-biasx","text":"BiasX is a Python library designed for the comprehensive analysis of gender bias in face classification models. It provides a pipeline to evaluate model performance, generate visual explanations for model decisions, and calculate quantitative bias metrics. Understanding and mitigating bias in AI models is crucial, especially in sensitive applications like facial recognition. BiasX aims to provide researchers and developers with the tools needed to identify how and why their models might exhibit different behaviors across demographic groups.","title":"Welcome to BiasX"},{"location":"#key-features","text":"Model Loading & Inference: Handles loading TensorFlow/Keras models and running predictions. Dataset Management: Loads and preprocesses standard facial image datasets like UTKFace and FairFace. Visual Explanations: Generates Class Activation Maps (CAMs) using methods like GradCAM, GradCAM++, and ScoreCAM to highlight regions influencing predictions. Detects facial landmarks (eyes, nose, mouth, etc.) using providers like MediaPipe. Bias Calculation: Analyzes the correlation between activated facial features and misclassifications across genders. Calculates overall bias disparity scores, including Equalized Odds. Configurable Pipeline: Allows easy configuration of datasets, models, explanation methods, and analysis parameters through YAML files or Python dictionaries.","title":"Key Features"},{"location":"#getting-started","text":"New to BiasX? Start with the Getting Started guide to walk through a basic analysis example. Check the Installation guide for setup instructions. Explore the Configuration options to customize the analysis pipeline. Dive deep into the components with the API Reference .","title":"Getting Started"},{"location":"configuration/","text":"Configuration BiasX uses a configuration system to manage parameters for datasets, models, explainers, and calculators. You can configure the BiasAnalyzer either by passing a Python dictionary directly during instantiation or by loading settings from a configuration file (commonly YAML, though JSON is also supported via utility functions). Configuration Structure The configuration is typically structured with top-level keys corresponding to the main components: dataset , model , explainer , and calculator . # Example Structure (Python Dictionary) config = { \"dataset\": { # Dataset parameters... }, \"model\": { # Model parameters... }, \"explainer\": { # Explainer parameters... }, \"calculator\": { # Calculator parameters... }, \"analyzer\": { # Optional: Parameters directly for BiasAnalyzer itself \"batch_size\": 32 } } # Example Instantiation from biasx import BiasAnalyzer analyzer = BiasAnalyzer(config=config) # Example Instantiation from file analyzer_from_file = BiasAnalyzer.from_file(\"path/to/your/config.yaml\") # Component Configuration Details Each component class uses the @configurable decorator, meaning its __init__ parameters can be set via the configuration dictionary under the corresponding key ( dataset , model , explainer , calculator ). Dataset ( dataset ) Parameters for the biasx.datasets.Dataset class. source : (Required) The source dataset to use. Should correspond to values in the DatasetSource enum (e.g., \"utkface\" , \"fairface\" ). image_width : (Required) The target width to resize images to. image_height : (Required) The target height to resize images to. color_mode : (Required) The target color mode. Should correspond to values in the ColorMode enum (e.g., \"L\" for grayscale, \"RGB\" for color). max_samples : (Optional) Maximum number of samples to load from the dataset. If 0 or less, all samples are loaded. Defaults depend on the implementation, but often it's useful to set a smaller number for testing (e.g., 100 ). shuffle : (Optional) Whether to shuffle the dataset before selecting max_samples or iterating. Defaults to False . seed : (Optional) Random seed used for shuffling if shuffle is True . Defaults depend on implementation (e.g., 42 ). batch_size : (Optional) The number of images yielded per iteration when iterating over the dataset. Defaults depend on implementation (e.g., 32 ). Model ( model ) Parameters for the biasx.models.Model class. path : (Required) Filesystem path to the saved Keras/TensorFlow model file (e.g., .h5 or a SavedModel directory). inverted_classes : (Required) Boolean indicating if the model's output class indices for Male/Female are inverted compared to the Gender enum (Male=0, Female=1). Set to True if your model predicts Female as 0 and Male as 1. batch_size : (Optional) Batch size used for model prediction ( model.predict ). Defaults depend on implementation (e.g., 64 ). Explainer ( explainer ) Parameters for the biasx.explainers.Explainer class. landmarker_source : (Required) Specifies the facial landmark detection model source. Should correspond to values in the LandmarkerSource enum (e.g., \"mediapipe\" ). cam_method : (Required) Specifies the Class Activation Map method to use. Should correspond to values in the CAMMethod enum (e.g., \"gradcam\" , \"gradcam++\" , \"scorecam\" ). cutoff_percentile : (Required) Integer percentile (0-100) used to threshold the raw activation map. Pixels below this percentile intensity are set to zero. threshold_method : (Required) Specifies the method used to binarize the thresholded activation map to find distinct activation regions. Should correspond to values in the ThresholdMethod enum (e.g., \"otsu\" , \"sauvola\" , \"triangle\" ). overlap_threshold : (Required) Float value (0.0-1.0) determining the minimum overlap area (as a fraction of the activation box area) required to associate an activation box with a landmark box. distance_metric : (Required) Specifies the distance metric used to find the nearest landmark center to an activation center. Should correspond to values in the DistanceMetric enum (e.g., \"cityblock\" , \"cosine\" , \"euclidean\" ). batch_size : (Optional) Batch size used during the explanation generation process (specifically for CAM generation). Defaults depend on implementation (e.g., 32 ). Calculator ( calculator ) Parameters for the biasx.calculators.Calculator class. precision : (Required) Integer specifying the number of decimal places to round calculated bias scores and probabilities to. Analyzer ( analyzer ) Optional parameters directly for the biasx.analyzer.BiasAnalyzer class itself. batch_size : (Optional) Controls the batch size used when iterating through the dataset within the analyzer's main analyze loop. This is distinct from the dataset's own iteration batch size or the model/explainer batch sizes. Defaults depend on implementation (e.g., 32 ). Example Configuration File ( config.yaml ) # Dataset Configuration dataset: source: utkface # Source dataset name (enum value) max_samples: 5000 # Max images to load (0 for all) shuffle: true # Shuffle before selecting max_samples seed: 42 # Random seed for shuffling image_width: 48 # Target image width image_height: 48 # Target image height color_mode: \"L\" # \"L\" for grayscale, \"RGB\" for color batch_size: 64 # Batch size for dataset iteration # Model Configuration model: path: \"./models/my_face_classifier.h5\" # Path to your trained model inverted_classes: false # Does your model output 0=Female, 1=Male? batch_size: 128 # Batch size for model.predict() # Explainer Configuration explainer: landmarker_source: mediapipe # Source for facial landmarks cam_method: gradcam++ # CAM method (gradcam, gradcam++, scorecam) cutoff_percentile: 95 # Percentile for CAM heatmap thresholding threshold_method: otsu # Method to binarize heatmap (otsu, sauvola, triangle) overlap_threshold: 0.3 # Min overlap to link activation box to landmark distance_metric: euclidean # Metric for nearest landmark (cityblock, cosine, euclidean) batch_size: 64 # Batch size for CAM generation # Calculator Configuration calculator: precision: 4 # Decimal places for calculated scores # Analyzer Configuration (Optional) analyzer: batch_size: 64 # Batch size for the main analysis loop","title":"Configuration"},{"location":"configuration/#configuration","text":"BiasX uses a configuration system to manage parameters for datasets, models, explainers, and calculators. You can configure the BiasAnalyzer either by passing a Python dictionary directly during instantiation or by loading settings from a configuration file (commonly YAML, though JSON is also supported via utility functions).","title":"Configuration"},{"location":"configuration/#configuration-structure","text":"The configuration is typically structured with top-level keys corresponding to the main components: dataset , model , explainer , and calculator . # Example Structure (Python Dictionary) config = { \"dataset\": { # Dataset parameters... }, \"model\": { # Model parameters... }, \"explainer\": { # Explainer parameters... }, \"calculator\": { # Calculator parameters... }, \"analyzer\": { # Optional: Parameters directly for BiasAnalyzer itself \"batch_size\": 32 } } # Example Instantiation from biasx import BiasAnalyzer analyzer = BiasAnalyzer(config=config) # Example Instantiation from file analyzer_from_file = BiasAnalyzer.from_file(\"path/to/your/config.yaml\") #","title":"Configuration Structure"},{"location":"configuration/#component-configuration-details","text":"Each component class uses the @configurable decorator, meaning its __init__ parameters can be set via the configuration dictionary under the corresponding key ( dataset , model , explainer , calculator ).","title":"Component Configuration Details"},{"location":"configuration/#dataset-dataset","text":"Parameters for the biasx.datasets.Dataset class. source : (Required) The source dataset to use. Should correspond to values in the DatasetSource enum (e.g., \"utkface\" , \"fairface\" ). image_width : (Required) The target width to resize images to. image_height : (Required) The target height to resize images to. color_mode : (Required) The target color mode. Should correspond to values in the ColorMode enum (e.g., \"L\" for grayscale, \"RGB\" for color). max_samples : (Optional) Maximum number of samples to load from the dataset. If 0 or less, all samples are loaded. Defaults depend on the implementation, but often it's useful to set a smaller number for testing (e.g., 100 ). shuffle : (Optional) Whether to shuffle the dataset before selecting max_samples or iterating. Defaults to False . seed : (Optional) Random seed used for shuffling if shuffle is True . Defaults depend on implementation (e.g., 42 ). batch_size : (Optional) The number of images yielded per iteration when iterating over the dataset. Defaults depend on implementation (e.g., 32 ).","title":"Dataset (dataset)"},{"location":"configuration/#model-model","text":"Parameters for the biasx.models.Model class. path : (Required) Filesystem path to the saved Keras/TensorFlow model file (e.g., .h5 or a SavedModel directory). inverted_classes : (Required) Boolean indicating if the model's output class indices for Male/Female are inverted compared to the Gender enum (Male=0, Female=1). Set to True if your model predicts Female as 0 and Male as 1. batch_size : (Optional) Batch size used for model prediction ( model.predict ). Defaults depend on implementation (e.g., 64 ).","title":"Model (model)"},{"location":"configuration/#explainer-explainer","text":"Parameters for the biasx.explainers.Explainer class. landmarker_source : (Required) Specifies the facial landmark detection model source. Should correspond to values in the LandmarkerSource enum (e.g., \"mediapipe\" ). cam_method : (Required) Specifies the Class Activation Map method to use. Should correspond to values in the CAMMethod enum (e.g., \"gradcam\" , \"gradcam++\" , \"scorecam\" ). cutoff_percentile : (Required) Integer percentile (0-100) used to threshold the raw activation map. Pixels below this percentile intensity are set to zero. threshold_method : (Required) Specifies the method used to binarize the thresholded activation map to find distinct activation regions. Should correspond to values in the ThresholdMethod enum (e.g., \"otsu\" , \"sauvola\" , \"triangle\" ). overlap_threshold : (Required) Float value (0.0-1.0) determining the minimum overlap area (as a fraction of the activation box area) required to associate an activation box with a landmark box. distance_metric : (Required) Specifies the distance metric used to find the nearest landmark center to an activation center. Should correspond to values in the DistanceMetric enum (e.g., \"cityblock\" , \"cosine\" , \"euclidean\" ). batch_size : (Optional) Batch size used during the explanation generation process (specifically for CAM generation). Defaults depend on implementation (e.g., 32 ).","title":"Explainer (explainer)"},{"location":"configuration/#calculator-calculator","text":"Parameters for the biasx.calculators.Calculator class. precision : (Required) Integer specifying the number of decimal places to round calculated bias scores and probabilities to.","title":"Calculator (calculator)"},{"location":"configuration/#analyzer-analyzer","text":"Optional parameters directly for the biasx.analyzer.BiasAnalyzer class itself. batch_size : (Optional) Controls the batch size used when iterating through the dataset within the analyzer's main analyze loop. This is distinct from the dataset's own iteration batch size or the model/explainer batch sizes. Defaults depend on implementation (e.g., 32 ).","title":"Analyzer (analyzer)"},{"location":"configuration/#example-configuration-file-configyaml","text":"# Dataset Configuration dataset: source: utkface # Source dataset name (enum value) max_samples: 5000 # Max images to load (0 for all) shuffle: true # Shuffle before selecting max_samples seed: 42 # Random seed for shuffling image_width: 48 # Target image width image_height: 48 # Target image height color_mode: \"L\" # \"L\" for grayscale, \"RGB\" for color batch_size: 64 # Batch size for dataset iteration # Model Configuration model: path: \"./models/my_face_classifier.h5\" # Path to your trained model inverted_classes: false # Does your model output 0=Female, 1=Male? batch_size: 128 # Batch size for model.predict() # Explainer Configuration explainer: landmarker_source: mediapipe # Source for facial landmarks cam_method: gradcam++ # CAM method (gradcam, gradcam++, scorecam) cutoff_percentile: 95 # Percentile for CAM heatmap thresholding threshold_method: otsu # Method to binarize heatmap (otsu, sauvola, triangle) overlap_threshold: 0.3 # Min overlap to link activation box to landmark distance_metric: euclidean # Metric for nearest landmark (cityblock, cosine, euclidean) batch_size: 64 # Batch size for CAM generation # Calculator Configuration calculator: precision: 4 # Decimal places for calculated scores # Analyzer Configuration (Optional) analyzer: batch_size: 64 # Batch size for the main analysis loop","title":"Example Configuration File (config.yaml)"},{"location":"getting_started/","text":"Getting Started with BiasX This guide provides a basic example of how to perform a gender bias analysis using the BiasX package. Prerequisites Ensure you have installed BiasX. If not, please follow the Installation guide. First, import the main analyzer class: from biasx import BiasAnalyzer from biasx.types import DatasetSource, CAMMethod, LandmarkerSource # Import necessary enums Basic Analysis Workflow Here's a minimal example demonstrating the core steps: Define Configuration Instead of a separate file, we can define the configuration directly as a Python dictionary for simplicity. We'll use the UTKFace dataset, GradCAM for explanations, and limit the analysis to 100 samples for speed. # Define minimal configuration for the example config = { \"dataset\": { \"source\": DatasetSource.UTKFACE.value, # Specify the dataset source \"max_samples\": 100, # Limit samples for a quick run \"image_width\": 48, # Example image size \"image_height\": 48, \"color_mode\": \"L\", # Example: Use grayscale \"batch_size\": 32 # Example batch size }, \"model\": { \"path\": \"path/to/your/face_model.h5\", # IMPORTANT: Replace with the actual path to your Keras model \"inverted_classes\": False, # Set based on your model's output \"batch_size\": 32 # Model prediction batch size }, \"explainer\": { \"landmarker_source\": LandmarkerSource.MEDIAPIPE.value, # Use MediaPipe for landmarks \"cam_method\": CAMMethod.GRADCAM.value, # Use GradCAM for explanations \"cutoff_percentile\": 90, # Example CAM cutoff \"threshold_method\": \"otsu\", # Example thresholding \"overlap_threshold\": 0.5, # Example overlap threshold \"distance_metric\": \"euclidean\", # Example distance metric \"batch_size\": 32 # Explainer processing batch size }, \"calculator\": { \"precision\": 4 # Example precision for calculations } # Output configuration defaults are often sufficient for getting started } Note: Remember to replace \"path/to/your/face_model.h5\" with the actual path to your trained face classification model. Instantiate the Analyzer Create an instance of BiasAnalyzer , passing the configuration dictionary. analyzer = BiasAnalyzer(config=config) Run the Analysis Execute the full analysis pipeline. This will load the dataset, run predictions, generate explanations (landmarks and activation maps), and calculate bias metrics. results = analyzer.analyze() Inspect Results The analyze method returns an AnalysisResult object containing detailed findings. You can inspect overall scores or dive into feature-specific analyses. # Print the overall BiasX disparity score print(f\"Overall BiasX Score: {results.disparity_scores.biasx}\") # Print the bias score calculated for a specific feature, e.g., the nose if \"nose\" in results.feature_analyses: nose_analysis = results.feature_analyses[\"nose\"] print(f\"Nose Bias Score: {nose_analysis.bias_score}\") print(f\" - Male Probability (Nose): {nose_analysis.male_probability}\") print(f\" - Female Probability (Nose): {nose_analysis.female_probability}\") # Explore detailed explanations for each image (optional) # for explanation in results.explanations: # print(f\"Image ID: {explanation.image_data.image_id}, Predicted: {explanation.predicted_gender}\") # # Access explanation.activation_boxes, explanation.landmark_boxes etc. Next Steps Explore the Configuration page for a detailed overview of all available settings. Dive into the specifics of each component in the API Reference .","title":"Getting Started"},{"location":"getting_started/#getting-started-with-biasx","text":"This guide provides a basic example of how to perform a gender bias analysis using the BiasX package.","title":"Getting Started with BiasX"},{"location":"getting_started/#prerequisites","text":"Ensure you have installed BiasX. If not, please follow the Installation guide. First, import the main analyzer class: from biasx import BiasAnalyzer from biasx.types import DatasetSource, CAMMethod, LandmarkerSource # Import necessary enums","title":"Prerequisites"},{"location":"getting_started/#basic-analysis-workflow","text":"Here's a minimal example demonstrating the core steps:","title":"Basic Analysis Workflow"},{"location":"getting_started/#define-configuration","text":"Instead of a separate file, we can define the configuration directly as a Python dictionary for simplicity. We'll use the UTKFace dataset, GradCAM for explanations, and limit the analysis to 100 samples for speed. # Define minimal configuration for the example config = { \"dataset\": { \"source\": DatasetSource.UTKFACE.value, # Specify the dataset source \"max_samples\": 100, # Limit samples for a quick run \"image_width\": 48, # Example image size \"image_height\": 48, \"color_mode\": \"L\", # Example: Use grayscale \"batch_size\": 32 # Example batch size }, \"model\": { \"path\": \"path/to/your/face_model.h5\", # IMPORTANT: Replace with the actual path to your Keras model \"inverted_classes\": False, # Set based on your model's output \"batch_size\": 32 # Model prediction batch size }, \"explainer\": { \"landmarker_source\": LandmarkerSource.MEDIAPIPE.value, # Use MediaPipe for landmarks \"cam_method\": CAMMethod.GRADCAM.value, # Use GradCAM for explanations \"cutoff_percentile\": 90, # Example CAM cutoff \"threshold_method\": \"otsu\", # Example thresholding \"overlap_threshold\": 0.5, # Example overlap threshold \"distance_metric\": \"euclidean\", # Example distance metric \"batch_size\": 32 # Explainer processing batch size }, \"calculator\": { \"precision\": 4 # Example precision for calculations } # Output configuration defaults are often sufficient for getting started } Note: Remember to replace \"path/to/your/face_model.h5\" with the actual path to your trained face classification model.","title":"Define Configuration"},{"location":"getting_started/#instantiate-the-analyzer","text":"Create an instance of BiasAnalyzer , passing the configuration dictionary. analyzer = BiasAnalyzer(config=config)","title":"Instantiate the Analyzer"},{"location":"getting_started/#run-the-analysis","text":"Execute the full analysis pipeline. This will load the dataset, run predictions, generate explanations (landmarks and activation maps), and calculate bias metrics. results = analyzer.analyze()","title":"Run the Analysis"},{"location":"getting_started/#inspect-results","text":"The analyze method returns an AnalysisResult object containing detailed findings. You can inspect overall scores or dive into feature-specific analyses. # Print the overall BiasX disparity score print(f\"Overall BiasX Score: {results.disparity_scores.biasx}\") # Print the bias score calculated for a specific feature, e.g., the nose if \"nose\" in results.feature_analyses: nose_analysis = results.feature_analyses[\"nose\"] print(f\"Nose Bias Score: {nose_analysis.bias_score}\") print(f\" - Male Probability (Nose): {nose_analysis.male_probability}\") print(f\" - Female Probability (Nose): {nose_analysis.female_probability}\") # Explore detailed explanations for each image (optional) # for explanation in results.explanations: # print(f\"Image ID: {explanation.image_data.image_id}, Predicted: {explanation.predicted_gender}\") # # Access explanation.activation_boxes, explanation.landmark_boxes etc.","title":"Inspect Results"},{"location":"getting_started/#next-steps","text":"Explore the Configuration page for a detailed overview of all available settings. Dive into the specifics of each component in the API Reference .","title":"Next Steps"},{"location":"installation/","text":"Installation This guide will walk you through installing the BiasX package. Requirements Before installing BiasX, ensure you have the following prerequisites installed on your system: Python: A recent version of Python (e.g., 3.8 or later is recommended). pip: The Python package installer. This usually comes bundled with modern Python versions. You can check your installations by running: python --version pip --version If you need to install Python, please visit python.org . If you need to install or upgrade pip, follow the instructions on the pip documentation . Installing BiasX You can install the BiasX package directly from PyPI using pip: pip install biasx This command will download and install BiasX along with its necessary dependencies (such as TensorFlow, NumPy, MediaPipe, Hugging Face Hub, etc.). Verifying the Installation (Optional) To verify that BiasX was installed correctly, you can open a Python interpreter and try importing the main class: try: from biasx import BiasAnalyzer print(\"BiasX installed successfully!\") except ImportError: print(\"Error: BiasX not found. Please check your installation.\") You are now ready to start using BiasX! Head over to the Getting Started guide for a basic usage example.","title":"Installation"},{"location":"installation/#installation","text":"This guide will walk you through installing the BiasX package.","title":"Installation"},{"location":"installation/#requirements","text":"Before installing BiasX, ensure you have the following prerequisites installed on your system: Python: A recent version of Python (e.g., 3.8 or later is recommended). pip: The Python package installer. This usually comes bundled with modern Python versions. You can check your installations by running: python --version pip --version If you need to install Python, please visit python.org . If you need to install or upgrade pip, follow the instructions on the pip documentation .","title":"Requirements"},{"location":"installation/#installing-biasx","text":"You can install the BiasX package directly from PyPI using pip: pip install biasx This command will download and install BiasX along with its necessary dependencies (such as TensorFlow, NumPy, MediaPipe, Hugging Face Hub, etc.).","title":"Installing BiasX"},{"location":"installation/#verifying-the-installation-optional","text":"To verify that BiasX was installed correctly, you can open a Python interpreter and try importing the main class: try: from biasx import BiasAnalyzer print(\"BiasX installed successfully!\") except ImportError: print(\"Error: BiasX not found. Please check your installation.\") You are now ready to start using BiasX! Head over to the Getting Started guide for a basic usage example.","title":"Verifying the Installation (Optional)"},{"location":"api/analyzer/","text":"Bias Analyzer This module contains the main orchestrator for the bias analysis pipeline. biasx.analyzer.BiasAnalyzer Orchestrates the end-to-end facial recognition bias analysis pipeline. This class coordinates the process of loading data, running model inference, generating visual explanations (activation maps and facial landmarks), and calculating various bias metrics. It integrates functionalities from Dataset, Model, Explainer, and Calculator components. Attributes: config ( Config ) \u2013 The configuration object holding settings for all components (dataset, model, explainer, calculator). model ( Model ) \u2013 An instance of the Model class for performing inference. dataset ( Dataset ) \u2013 An instance of the Dataset class for loading and preprocessing data. explainer ( Explainer ) \u2013 An instance of the Explainer class for generating visual explanations. calculator ( Calculator ) \u2013 An instance of the Calculator class for computing bias metrics. batch_size ( int ) \u2013 The batch size used for processing data during analysis, potentially overriding batch sizes specified in component configurations for the analysis loop itself. Examples: >>> # Using a configuration dictionary >>> config_dict = { ... \"dataset\" : { \"source\" : \"utkface\" , \"max_samples\" : 100 }, ... \"model\" : { \"path\" : \"/path/to/model.h5\" }, ... \"explainer\" : { \"cam_method\" : \"gradcam\" }, ... \"calculator\" : { \"precision\" : 4 }, ... \"analyzer\" : { \"batch_size\" : 16 } ... } # >>> analyzer = BiasAnalyzer ( config = config_dict ) >>> results = analyzer . analyze () >>> print ( results . disparity_scores ) >>> # Using a configuration file >>> analyzer = BiasAnalyzer . from_file ( \"config.yaml\" ) # >>> results = analyzer . analyze () >>> print ( f \"BiasX Score: { results . disparity_scores . biasx } \" ) __init__ ( config = None , batch_size = 32 , ** kwargs ) Initializes the BiasAnalyzer and its components. Sets up the Dataset, Model, Explainer, and Calculator based on the provided configuration. Parameters: config ( Union [ Config , Dict , None] , default: None ) \u2013 A configuration object (Config) or dictionary containing settings for the analyzer and its sub-components (Dataset, Model, Explainer, Calculator). If None, default configurations might be used or an error raised depending on the Config setup. Defaults to None. batch_size ( int , default: 32 ) \u2013 The batch size to use when iterating through the dataset during the analyze method. This primarily controls the batching within the analyzer's loop, distinct from potential batch sizes used internally by the model or explainer if configured differently. Defaults to 32. **kwargs \u2013 Additional keyword arguments, potentially used by the configurable decorator or passed down during component initialization if the Config structure supports it. analyze () Runs the full bias analysis pipeline on the configured dataset. This method iterates through the entire dataset provided by the Dataset component, processing images in batches using analyze_batch . It aggregates all the generated Explanation objects and then uses the Calculator component to compute feature-level bias analyses and overall disparity scores (like BiasX and Equalized Odds). Returns: AnalysisResult \u2013 An AnalysisResult object containing: explanations : A list of all Explanation objects generated for each image in the dataset. feature_analyses : A dictionary mapping each FacialFeature to its calculated FeatureAnalysis (bias score, per-gender probabilities). disparity_scores : A DisparityScores object containing overall metrics like BiasX and Equalized Odds. Returns an empty AnalysisResult if the dataset yields no data or no explanations could be generated. Note This method processes the entire dataset as configured in the Dataset component (respecting max_samples , shuffling, etc.). It can be computationally intensive depending on the dataset size and model complexity. It uses an internal buffer to manage memory usage during explanation aggregation. analyze_batch ( image_data_batch ) Analyzes a single batch of images through the pipeline. This method takes a list of ImageData objects, runs model prediction, generates explanations (activation maps, landmarks, labeled boxes), and compiles the results into Explanation objects. Parameters: image_data_batch ( List [ ImageData ] ) \u2013 A list of ImageData objects, typically obtained from iterating over a Dataset instance. Each ImageData object should contain at least the preprocessed image (NumPy array) and the original PIL image. Returns: List [ Explanation ] \u2013 A list of Explanation objects, one for each image in the input batch. Each Explanation object contains the original image data, prediction results (gender, confidence), activation map, activation boxes (potentially labeled with facial features), and landmark boxes. Returns an empty list if the input batch is empty. from_file ( config_file_path ) classmethod Creates a BiasAnalyzer instance from a configuration file. This factory method provides a convenient way to initialize the analyzer using an external configuration file (e.g., YAML, JSON) that defines the settings for all components. Parameters: config_file_path ( str ) \u2013 The path to the configuration file. The file format should be supported by the underlying Config class's from_file method. Returns: BiasAnalyzer \u2013 A new instance of BiasAnalyzer configured according to the file. Examples: >>> analyzer = BiasAnalyzer . from_file ( 'analysis_config.yaml' ) # >>> results = analyzer . analyze ()","title":"Analyzer"},{"location":"api/analyzer/#bias-analyzer","text":"This module contains the main orchestrator for the bias analysis pipeline.","title":"Bias Analyzer"},{"location":"api/analyzer/#biasx.analyzer.BiasAnalyzer","text":"Orchestrates the end-to-end facial recognition bias analysis pipeline. This class coordinates the process of loading data, running model inference, generating visual explanations (activation maps and facial landmarks), and calculating various bias metrics. It integrates functionalities from Dataset, Model, Explainer, and Calculator components. Attributes: config ( Config ) \u2013 The configuration object holding settings for all components (dataset, model, explainer, calculator). model ( Model ) \u2013 An instance of the Model class for performing inference. dataset ( Dataset ) \u2013 An instance of the Dataset class for loading and preprocessing data. explainer ( Explainer ) \u2013 An instance of the Explainer class for generating visual explanations. calculator ( Calculator ) \u2013 An instance of the Calculator class for computing bias metrics. batch_size ( int ) \u2013 The batch size used for processing data during analysis, potentially overriding batch sizes specified in component configurations for the analysis loop itself. Examples: >>> # Using a configuration dictionary >>> config_dict = { ... \"dataset\" : { \"source\" : \"utkface\" , \"max_samples\" : 100 }, ... \"model\" : { \"path\" : \"/path/to/model.h5\" }, ... \"explainer\" : { \"cam_method\" : \"gradcam\" }, ... \"calculator\" : { \"precision\" : 4 }, ... \"analyzer\" : { \"batch_size\" : 16 } ... } # >>> analyzer = BiasAnalyzer ( config = config_dict ) >>> results = analyzer . analyze () >>> print ( results . disparity_scores ) >>> # Using a configuration file >>> analyzer = BiasAnalyzer . from_file ( \"config.yaml\" ) # >>> results = analyzer . analyze () >>> print ( f \"BiasX Score: { results . disparity_scores . biasx } \" )","title":"BiasAnalyzer"},{"location":"api/analyzer/#biasx.analyzer.BiasAnalyzer.__init__","text":"Initializes the BiasAnalyzer and its components. Sets up the Dataset, Model, Explainer, and Calculator based on the provided configuration. Parameters: config ( Union [ Config , Dict , None] , default: None ) \u2013 A configuration object (Config) or dictionary containing settings for the analyzer and its sub-components (Dataset, Model, Explainer, Calculator). If None, default configurations might be used or an error raised depending on the Config setup. Defaults to None. batch_size ( int , default: 32 ) \u2013 The batch size to use when iterating through the dataset during the analyze method. This primarily controls the batching within the analyzer's loop, distinct from potential batch sizes used internally by the model or explainer if configured differently. Defaults to 32. **kwargs \u2013 Additional keyword arguments, potentially used by the configurable decorator or passed down during component initialization if the Config structure supports it.","title":"__init__"},{"location":"api/analyzer/#biasx.analyzer.BiasAnalyzer.analyze","text":"Runs the full bias analysis pipeline on the configured dataset. This method iterates through the entire dataset provided by the Dataset component, processing images in batches using analyze_batch . It aggregates all the generated Explanation objects and then uses the Calculator component to compute feature-level bias analyses and overall disparity scores (like BiasX and Equalized Odds). Returns: AnalysisResult \u2013 An AnalysisResult object containing: explanations : A list of all Explanation objects generated for each image in the dataset. feature_analyses : A dictionary mapping each FacialFeature to its calculated FeatureAnalysis (bias score, per-gender probabilities). disparity_scores : A DisparityScores object containing overall metrics like BiasX and Equalized Odds. Returns an empty AnalysisResult if the dataset yields no data or no explanations could be generated. Note This method processes the entire dataset as configured in the Dataset component (respecting max_samples , shuffling, etc.). It can be computationally intensive depending on the dataset size and model complexity. It uses an internal buffer to manage memory usage during explanation aggregation.","title":"analyze"},{"location":"api/analyzer/#biasx.analyzer.BiasAnalyzer.analyze_batch","text":"Analyzes a single batch of images through the pipeline. This method takes a list of ImageData objects, runs model prediction, generates explanations (activation maps, landmarks, labeled boxes), and compiles the results into Explanation objects. Parameters: image_data_batch ( List [ ImageData ] ) \u2013 A list of ImageData objects, typically obtained from iterating over a Dataset instance. Each ImageData object should contain at least the preprocessed image (NumPy array) and the original PIL image. Returns: List [ Explanation ] \u2013 A list of Explanation objects, one for each image in the input batch. Each Explanation object contains the original image data, prediction results (gender, confidence), activation map, activation boxes (potentially labeled with facial features), and landmark boxes. Returns an empty list if the input batch is empty.","title":"analyze_batch"},{"location":"api/analyzer/#biasx.analyzer.BiasAnalyzer.from_file","text":"Creates a BiasAnalyzer instance from a configuration file. This factory method provides a convenient way to initialize the analyzer using an external configuration file (e.g., YAML, JSON) that defines the settings for all components. Parameters: config_file_path ( str ) \u2013 The path to the configuration file. The file format should be supported by the underlying Config class's from_file method. Returns: BiasAnalyzer \u2013 A new instance of BiasAnalyzer configured according to the file. Examples: >>> analyzer = BiasAnalyzer . from_file ( 'analysis_config.yaml' ) # >>> results = analyzer . analyze ()","title":"from_file"},{"location":"api/calculators/","text":"Calculators This module provides classes for calculating bias metrics based on model explanations. biasx.calculators.Calculator Calculates bias metrics based on model explanations and ground truth. This class takes the explanations generated by the Explainer component (which include image data, predictions, and activation/landmark details) and computes quantitative measures of bias. It calculates feature-specific bias scores and overall disparity metrics like BiasX and Equalized Odds. Attributes: precision ( int ) \u2013 The number of decimal places to round the calculated bias metrics to. __init__ ( precision , ** kwargs ) Initializes the bias Calculator. Parameters: precision ( int ) \u2013 The number of decimal places for rounding calculated bias scores and probabilities. **kwargs \u2013 Additional keyword arguments, potentially used by the configurable decorator or for future extensions. calculate_disparities ( feature_analyses , explanations ) Calculates overall disparity scores for the model. This method computes aggregate bias metrics based on the previously calculated feature-level analyses and the overall model performance across different gender groups. Parameters: feature_analyses ( Dict [ FacialFeature , FeatureAnalysis ] ) \u2013 A dictionary mapping FacialFeatures to their corresponding FeatureAnalysis objects, as returned by calculate_feature_biases . explanations ( List [ Explanation ] ) \u2013 A list of Explanation objects for all analyzed images, needed to calculate performance metrics like Equalized Odds. Returns: DisparityScores \u2013 A DisparityScores object containing: biasx : An overall bias score calculated as the average of the absolute bias scores across all analyzed facial features. equalized_odds : A score measuring the maximum disparity in True Positive Rates (TPR) and False Positive Rates (FPR) between male and female groups. A score of 0 indicates perfect equality in error rates across genders. Returns default DisparityScores (often with 0 values) if no feature analyses are provided. calculate_feature_biases ( explanations ) Calculates bias metrics associated with each facial feature. This method analyzes how often different facial features are associated with model activations specifically during misclassifications for different gender groups (male vs. female). It determines the probability of a feature being activated when the model misclassifies an image of a certain true gender. The bias score for a feature reflects the absolute difference between these probabilities for males and females. Parameters: explanations ( List [ Explanation ] ) \u2013 A list of Explanation objects, containing the detailed analysis results for each image processed. Returns: Dict [ FacialFeature , FeatureAnalysis ] \u2013 A dictionary where keys are FacialFeature enums and values are FeatureAnalysis objects. Each FeatureAnalysis object contains: feature : The specific FacialFeature enum. bias_score : The absolute difference between male and female activation probabilities during misclassifications. male_probability : The probability of this feature being activated in misclassified male images. female_probability : The probability of this feature being activated in misclassified female images. Features with no observed activations during misclassifications are omitted from the result.","title":"Calculators"},{"location":"api/calculators/#calculators","text":"This module provides classes for calculating bias metrics based on model explanations.","title":"Calculators"},{"location":"api/calculators/#biasx.calculators.Calculator","text":"Calculates bias metrics based on model explanations and ground truth. This class takes the explanations generated by the Explainer component (which include image data, predictions, and activation/landmark details) and computes quantitative measures of bias. It calculates feature-specific bias scores and overall disparity metrics like BiasX and Equalized Odds. Attributes: precision ( int ) \u2013 The number of decimal places to round the calculated bias metrics to.","title":"Calculator"},{"location":"api/calculators/#biasx.calculators.Calculator.__init__","text":"Initializes the bias Calculator. Parameters: precision ( int ) \u2013 The number of decimal places for rounding calculated bias scores and probabilities. **kwargs \u2013 Additional keyword arguments, potentially used by the configurable decorator or for future extensions.","title":"__init__"},{"location":"api/calculators/#biasx.calculators.Calculator.calculate_disparities","text":"Calculates overall disparity scores for the model. This method computes aggregate bias metrics based on the previously calculated feature-level analyses and the overall model performance across different gender groups. Parameters: feature_analyses ( Dict [ FacialFeature , FeatureAnalysis ] ) \u2013 A dictionary mapping FacialFeatures to their corresponding FeatureAnalysis objects, as returned by calculate_feature_biases . explanations ( List [ Explanation ] ) \u2013 A list of Explanation objects for all analyzed images, needed to calculate performance metrics like Equalized Odds. Returns: DisparityScores \u2013 A DisparityScores object containing: biasx : An overall bias score calculated as the average of the absolute bias scores across all analyzed facial features. equalized_odds : A score measuring the maximum disparity in True Positive Rates (TPR) and False Positive Rates (FPR) between male and female groups. A score of 0 indicates perfect equality in error rates across genders. Returns default DisparityScores (often with 0 values) if no feature analyses are provided.","title":"calculate_disparities"},{"location":"api/calculators/#biasx.calculators.Calculator.calculate_feature_biases","text":"Calculates bias metrics associated with each facial feature. This method analyzes how often different facial features are associated with model activations specifically during misclassifications for different gender groups (male vs. female). It determines the probability of a feature being activated when the model misclassifies an image of a certain true gender. The bias score for a feature reflects the absolute difference between these probabilities for males and females. Parameters: explanations ( List [ Explanation ] ) \u2013 A list of Explanation objects, containing the detailed analysis results for each image processed. Returns: Dict [ FacialFeature , FeatureAnalysis ] \u2013 A dictionary where keys are FacialFeature enums and values are FeatureAnalysis objects. Each FeatureAnalysis object contains: feature : The specific FacialFeature enum. bias_score : The absolute difference between male and female activation probabilities during misclassifications. male_probability : The probability of this feature being activated in misclassified male images. female_probability : The probability of this feature being activated in misclassified female images. Features with no observed activations during misclassifications are omitted from the result.","title":"calculate_feature_biases"},{"location":"api/datasets/","text":"Datasets This module handles loading and preprocessing image datasets. biasx.datasets.Dataset Manages facial image datasets and preprocessing for model input. Loads dataset information from configuration, handles fetching dataset files (e.g., Parquet files from HuggingFace Hub), allows sampling and shuffling, and provides an iterator to yield batches of processed image data ready for model consumption. Attributes: source ( str ) \u2013 The identifier for the dataset source (e.g., 'utkface'). image_width ( int ) \u2013 The target width to resize images to. image_height ( int ) \u2013 The target height to resize images to. color_mode ( ColorMode ) \u2013 The target color mode ('L' for grayscale, 'RGB'). single_channel ( bool ) \u2013 Flag indicating if the output NumPy array should always have a single channel dimension (relevant for grayscale). max_samples ( int ) \u2013 Maximum number of samples to load from the dataset. If <= 0, all samples are loaded. shuffle ( bool ) \u2013 Whether to shuffle the dataset before sampling or iteration. seed ( int ) \u2013 Random seed used for shuffling if shuffle is True. batch_size ( int ) \u2013 The number of images to yield in each batch during iteration. dataset_info ( ResourceMetadata ) \u2013 Metadata loaded from configuration about the dataset resource (repo ID, filename, column names, etc.). dataset_path ( str ) \u2013 The local path to the downloaded dataset file. dataframe ( DataFrame ) \u2013 The pandas DataFrame holding the dataset metadata (after potential sampling and shuffling). __init__ ( source , image_width , image_height , color_mode , single_channel , max_samples , shuffle , seed , batch_size , ** kwargs ) Initialize the dataset with configuration and preprocessing parameters. Loads dataset metadata, potentially samples and shuffles the data based on configuration, and sets up image processing parameters. Parameters: source ( str ) \u2013 Identifier for the dataset source (e.g., \"utkface\"). Must correspond to an entry in dataset_config.json . image_width ( int ) \u2013 Target width for images after resizing. image_height ( int ) \u2013 Target height for images after resizing. color_mode ( ColorMode ) \u2013 Target color mode for images (e.g., ColorMode.GRAYSCALE). single_channel ( bool ) \u2013 If True and color_mode is GRAYSCALE, ensures the preprocessed numpy array has a channel dim. max_samples ( int ) \u2013 The maximum number of samples to use from the dataset. If 0 or negative, uses all samples. shuffle ( bool ) \u2013 Whether to shuffle the dataset records. seed ( int ) \u2013 The random seed to use for shuffling if shuffle is True. batch_size ( int ) \u2013 The number of samples per batch for the iterator. **kwargs \u2013 Additional keyword arguments passed via configuration. __iter__ () Iterate through the dataset, yielding batches of ImageData objects. Iterates over the internal DataFrame in steps of self.batch_size . For each batch, it loads the PIL images, preprocesses them into a NumPy array, extracts metadata, and then constructs a list of ImageData objects, where each object contains the ID, PIL image, preprocessed NumPy array slice, dimensions, and demographic labels for one sample. Yields: List [ ImageData ] \u2013 A list of biasx.types.ImageData objects representing one batch of data. The list length will be equal to self.batch_size , except possibly for the last batch. __len__ () Return the number of images in the configured dataset. Returns the total number of samples in the DataFrame after loading, sampling, and shuffling have been applied. Returns: int \u2013 The number of samples in the dataset.","title":"Datasets"},{"location":"api/datasets/#datasets","text":"This module handles loading and preprocessing image datasets.","title":"Datasets"},{"location":"api/datasets/#biasx.datasets.Dataset","text":"Manages facial image datasets and preprocessing for model input. Loads dataset information from configuration, handles fetching dataset files (e.g., Parquet files from HuggingFace Hub), allows sampling and shuffling, and provides an iterator to yield batches of processed image data ready for model consumption. Attributes: source ( str ) \u2013 The identifier for the dataset source (e.g., 'utkface'). image_width ( int ) \u2013 The target width to resize images to. image_height ( int ) \u2013 The target height to resize images to. color_mode ( ColorMode ) \u2013 The target color mode ('L' for grayscale, 'RGB'). single_channel ( bool ) \u2013 Flag indicating if the output NumPy array should always have a single channel dimension (relevant for grayscale). max_samples ( int ) \u2013 Maximum number of samples to load from the dataset. If <= 0, all samples are loaded. shuffle ( bool ) \u2013 Whether to shuffle the dataset before sampling or iteration. seed ( int ) \u2013 Random seed used for shuffling if shuffle is True. batch_size ( int ) \u2013 The number of images to yield in each batch during iteration. dataset_info ( ResourceMetadata ) \u2013 Metadata loaded from configuration about the dataset resource (repo ID, filename, column names, etc.). dataset_path ( str ) \u2013 The local path to the downloaded dataset file. dataframe ( DataFrame ) \u2013 The pandas DataFrame holding the dataset metadata (after potential sampling and shuffling).","title":"Dataset"},{"location":"api/datasets/#biasx.datasets.Dataset.__init__","text":"Initialize the dataset with configuration and preprocessing parameters. Loads dataset metadata, potentially samples and shuffles the data based on configuration, and sets up image processing parameters. Parameters: source ( str ) \u2013 Identifier for the dataset source (e.g., \"utkface\"). Must correspond to an entry in dataset_config.json . image_width ( int ) \u2013 Target width for images after resizing. image_height ( int ) \u2013 Target height for images after resizing. color_mode ( ColorMode ) \u2013 Target color mode for images (e.g., ColorMode.GRAYSCALE). single_channel ( bool ) \u2013 If True and color_mode is GRAYSCALE, ensures the preprocessed numpy array has a channel dim. max_samples ( int ) \u2013 The maximum number of samples to use from the dataset. If 0 or negative, uses all samples. shuffle ( bool ) \u2013 Whether to shuffle the dataset records. seed ( int ) \u2013 The random seed to use for shuffling if shuffle is True. batch_size ( int ) \u2013 The number of samples per batch for the iterator. **kwargs \u2013 Additional keyword arguments passed via configuration.","title":"__init__"},{"location":"api/datasets/#biasx.datasets.Dataset.__iter__","text":"Iterate through the dataset, yielding batches of ImageData objects. Iterates over the internal DataFrame in steps of self.batch_size . For each batch, it loads the PIL images, preprocesses them into a NumPy array, extracts metadata, and then constructs a list of ImageData objects, where each object contains the ID, PIL image, preprocessed NumPy array slice, dimensions, and demographic labels for one sample. Yields: List [ ImageData ] \u2013 A list of biasx.types.ImageData objects representing one batch of data. The list length will be equal to self.batch_size , except possibly for the last batch.","title":"__iter__"},{"location":"api/datasets/#biasx.datasets.Dataset.__len__","text":"Return the number of images in the configured dataset. Returns the total number of samples in the DataFrame after loading, sampling, and shuffling have been applied. Returns: int \u2013 The number of samples in the dataset.","title":"__len__"},{"location":"api/explainers/","text":"Explainers This module provides classes for generating visual explanations like activation maps and detecting facial landmarks. Explainer biasx.explainers.Explainer Coordinates the generation of visual explanations for model decisions. This class integrates the FacialLandmarker and ClassActivationMapper to produce comprehensive explanations for a batch of images. It generates activation maps, processes them into activation boxes, detects landmark boxes, and attempts to label activation boxes based on their spatial overlap and proximity to landmark features. Attributes: landmarker ( FacialLandmarker ) \u2013 An instance for detecting facial landmarks. activation_mapper ( ClassActivationMapper ) \u2013 An instance for generating and processing activation maps. overlap_threshold ( float ) \u2013 The minimum Intersection over Area (IoA) threshold required between an activation box and a landmark box for the activation box to inherit the landmark's feature label. distance_metric ( str ) \u2013 The distance metric (e.g., 'euclidean', 'cityblock') used to find the nearest landmark box center for each activation box center. batch_size ( int ) \u2013 The batch size hint used within this explainer, potentially influencing internal operations if implemented differently later. (Note: Current explain_batch processes the whole input batch at once). __init__ ( landmarker_source , cam_method , cutoff_percentile , threshold_method , overlap_threshold , distance_metric , batch_size , ** kwargs ) Initialize the visual explainer and its components. Creates instances of FacialLandmarker and ClassActivationMapper based on the provided configuration parameters. Stores thresholds and metrics used for associating activation boxes with features. Parameters: landmarker_source ( LandmarkerSource ) \u2013 The source for the facial landmark model. cam_method ( CAMMethod ) \u2013 The class activation mapping method to use. cutoff_percentile ( int ) \u2013 The percentile threshold for heatmap processing. threshold_method ( ThresholdMethod ) \u2013 The binarization method for heatmap processing. overlap_threshold ( float ) \u2013 The IoA threshold (0.0 to 1.0) for labeling activation boxes based on landmark box overlap. distance_metric ( DistanceMetric ) \u2013 The metric for comparing box center distances. batch_size ( int ) \u2013 A batch size parameter (currently informational). **kwargs \u2013 Additional keyword arguments passed via configuration. explain_batch ( pil_images , preprocessed_images , model , target_classes ) Generate visual explanations for a batch of images. Orchestrates the explanation process for a batch: Generates activation maps using ClassActivationMapper . Processes maps into activation boxes using ClassActivationMapper . Detects landmark boxes using FacialLandmarker . For each image, attempts to assign a FacialFeature label to each activation box by finding the nearest landmark box (based on center distance) and checking if their spatial overlap (IoA) meets the overlap_threshold . Parameters: pil_images ( List [ Image ] ) \u2013 List of original PIL images in the batch. preprocessed_images ( List [ ndarray ] ) \u2013 List of corresponding preprocessed images (NumPy arrays) ready for model/CAM input. model ( Model ) \u2013 The model instance (needed by the activation mapper). target_classes ( List [ Gender ] ) \u2013 The target class (Gender) for generating the CAM for each corresponding image. Returns: Tuple [ List [ ndarray ], List [ List [ Box ]], List [ List [ Box ]]] \u2013 A tuple containing three lists, all aligned with the input batch order: List[np.ndarray]: Raw activation maps (heatmaps) for each image. List[List[biasx.types.Box]]: Activation boxes for each image. Boxes may have their feature attribute set if successfully labeled. List[List[biasx.types.Box]]: Landmark boxes for each image, with their feature attribute set by the landmarker. Returns ([], [], []) if the input pil_images list is empty. FacialLandmarker biasx.explainers.FacialLandmarker Detects facial landmarks using MediaPipe. This class loads a pre-trained MediaPipe face landmark model, specified via configuration, and provides a method to detect landmarks in images. It maps the detected landmark points to specific facial features based on a predefined mapping file. Attributes: source ( LandmarkerSource ) \u2013 The source identifier for the landmarker model used (e.g., MEDIAPIPE). landmarker_info ( ResourceMetadata ) \u2013 Metadata loaded from configuration about the landmarker model resource. model_path ( str ) \u2013 The local path to the downloaded landmarker model file. landmark_mapping ( Dict [ FacialFeature , List [ int ]] ) \u2013 A dictionary mapping facial features (enum) to lists of landmark indices provided by the MediaPipe model. detector ( FaceLandmarker ) \u2013 The initialized MediaPipe FaceLandmarker instance. __init__ ( source ) Initialize the facial landmark detector. Loads resources based on the specified source, sets up the MediaPipe FaceLandmarker options, and creates the detector instance. Parameters: source ( LandmarkerSource ) \u2013 The source of the landmarker model to use (e.g., LandmarkerSource.MEDIAPIPE). Corresponds to keys in landmarker_config.json . detect ( images ) Detect facial landmarks in one or more images. Takes a single PIL image or a list of PIL images, converts them into MediaPipe's Image format, and runs detection using the initialized landmarker. For each image where landmarks are detected, it converts the normalized landmark coordinates to pixel coordinates and groups them into bounding boxes based on the self.landmark_mapping for each facial feature. Parameters: images ( Union [ Image , List [ Image ]] ) \u2013 A single PIL image or a list of PIL images to process. Returns: List [ List [ Box ]] \u2013 A list of lists of Box objects. The outer list corresponds to the input images. Each inner list contains biasx.types.Box objects, one for each facial feature defined in the mapping, representing the bounding box encompassing the landmarks for that feature in the corresponding image. If no landmarks are detected in an image, its corresponding inner list will be empty. ClassActivationMapper biasx.explainers.ClassActivationMapper Generates and processes class activation maps (CAMs). This class uses a specified CAM generation method (e.g., Grad-CAM++, Score-CAM) from the tf-keras-vis library to produce heatmaps highlighting regions important for a model's classification decision. It also provides methods to process these heatmaps by applying thresholding and identifying contiguous activated regions as bounding boxes. Attributes: cam_method ( ModelVisualization ) \u2013 The instantiated CAM visualization object (e.g., GradcamPlusPlus) based on the configured method. cutoff_percentile ( int ) \u2013 The percentile value (0-100) used to determine the threshold for filtering low-activation areas in the heatmap. threshold_method ( Callable [[ ndarray ], Any ] ) \u2013 The thresholding function (e.g., skimage.filters.threshold_otsu) used to binarize the filtered heatmap. __init__ ( cam_method , cutoff_percentile , threshold_method ) Initialize the activation map generator and processor. Parameters: cam_method ( CAMMethod ) \u2013 The CAM algorithm to use (e.g., CAMMethod.GRADCAM_PLUS_PLUS). cutoff_percentile ( int ) \u2013 The percentile (0-100) to use for thresholding the raw heatmap. Activations below this percentile are zeroed out. threshold_method ( ThresholdMethod ) \u2013 The algorithm used to binarize the filtered heatmap (e.g., ThresholdMethod.OTSU). generate_heatmap ( model , preprocessed_images , target_classes ) Generate class activation maps (heatmaps) for preprocessed images. Uses the configured CAM method ( tf-keras-vis ) to generate heatmaps for the given images with respect to the specified target classes. It handles preparing the images and defining the score function for the visualizer. Parameters: model ( Model ) \u2013 The trained Keras model to explain. preprocessed_images ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single preprocessed image (NumPy array) or a list/batch of preprocessed images (NumPy array). Assumes images are normalized and correctly shaped. target_classes ( Union [ Gender , List [ Gender ]] ) \u2013 The target class(es) (Gender enum) for which to generate the heatmaps. If a single Gender is provided, it's used for all images in the batch. Returns: List [ ndarray ] \u2013 A list of NumPy arrays, where each array is a 2D heatmap corresponding to an input image. Returns an empty list if the input is empty. process_heatmap ( heatmaps , pil_images ) Process heatmaps into bounding boxes of activated regions. Takes raw heatmaps, applies a percentile cutoff threshold, binarizes the result using the configured thresholding method, identifies connected regions (blobs) in the binary map, and converts these regions into bounding boxes scaled to the original image dimensions. Parameters: heatmaps ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single 2D heatmap or a list of 2D heatmaps (NumPy arrays) as generated by generate_heatmap . pil_images ( List [ Image ] ) \u2013 A list of the original PIL images corresponding to the heatmaps, used to get dimensions for scaling. Must be the same length as the list of heatmaps. Returns: List [ List [ Box ]] \u2013 A list of lists of Box objects. The outer list corresponds to the input heatmaps/images. Each inner list contains biasx.types.Box objects representing the bounding boxes of activated regions found in the corresponding heatmap. Boxes do not have features assigned at this stage.","title":"Explainers"},{"location":"api/explainers/#explainers","text":"This module provides classes for generating visual explanations like activation maps and detecting facial landmarks.","title":"Explainers"},{"location":"api/explainers/#explainer","text":"","title":"Explainer"},{"location":"api/explainers/#biasx.explainers.Explainer","text":"Coordinates the generation of visual explanations for model decisions. This class integrates the FacialLandmarker and ClassActivationMapper to produce comprehensive explanations for a batch of images. It generates activation maps, processes them into activation boxes, detects landmark boxes, and attempts to label activation boxes based on their spatial overlap and proximity to landmark features. Attributes: landmarker ( FacialLandmarker ) \u2013 An instance for detecting facial landmarks. activation_mapper ( ClassActivationMapper ) \u2013 An instance for generating and processing activation maps. overlap_threshold ( float ) \u2013 The minimum Intersection over Area (IoA) threshold required between an activation box and a landmark box for the activation box to inherit the landmark's feature label. distance_metric ( str ) \u2013 The distance metric (e.g., 'euclidean', 'cityblock') used to find the nearest landmark box center for each activation box center. batch_size ( int ) \u2013 The batch size hint used within this explainer, potentially influencing internal operations if implemented differently later. (Note: Current explain_batch processes the whole input batch at once).","title":"Explainer"},{"location":"api/explainers/#biasx.explainers.Explainer.__init__","text":"Initialize the visual explainer and its components. Creates instances of FacialLandmarker and ClassActivationMapper based on the provided configuration parameters. Stores thresholds and metrics used for associating activation boxes with features. Parameters: landmarker_source ( LandmarkerSource ) \u2013 The source for the facial landmark model. cam_method ( CAMMethod ) \u2013 The class activation mapping method to use. cutoff_percentile ( int ) \u2013 The percentile threshold for heatmap processing. threshold_method ( ThresholdMethod ) \u2013 The binarization method for heatmap processing. overlap_threshold ( float ) \u2013 The IoA threshold (0.0 to 1.0) for labeling activation boxes based on landmark box overlap. distance_metric ( DistanceMetric ) \u2013 The metric for comparing box center distances. batch_size ( int ) \u2013 A batch size parameter (currently informational). **kwargs \u2013 Additional keyword arguments passed via configuration.","title":"__init__"},{"location":"api/explainers/#biasx.explainers.Explainer.explain_batch","text":"Generate visual explanations for a batch of images. Orchestrates the explanation process for a batch: Generates activation maps using ClassActivationMapper . Processes maps into activation boxes using ClassActivationMapper . Detects landmark boxes using FacialLandmarker . For each image, attempts to assign a FacialFeature label to each activation box by finding the nearest landmark box (based on center distance) and checking if their spatial overlap (IoA) meets the overlap_threshold . Parameters: pil_images ( List [ Image ] ) \u2013 List of original PIL images in the batch. preprocessed_images ( List [ ndarray ] ) \u2013 List of corresponding preprocessed images (NumPy arrays) ready for model/CAM input. model ( Model ) \u2013 The model instance (needed by the activation mapper). target_classes ( List [ Gender ] ) \u2013 The target class (Gender) for generating the CAM for each corresponding image. Returns: Tuple [ List [ ndarray ], List [ List [ Box ]], List [ List [ Box ]]] \u2013 A tuple containing three lists, all aligned with the input batch order: List[np.ndarray]: Raw activation maps (heatmaps) for each image. List[List[biasx.types.Box]]: Activation boxes for each image. Boxes may have their feature attribute set if successfully labeled. List[List[biasx.types.Box]]: Landmark boxes for each image, with their feature attribute set by the landmarker. Returns ([], [], []) if the input pil_images list is empty.","title":"explain_batch"},{"location":"api/explainers/#faciallandmarker","text":"","title":"FacialLandmarker"},{"location":"api/explainers/#biasx.explainers.FacialLandmarker","text":"Detects facial landmarks using MediaPipe. This class loads a pre-trained MediaPipe face landmark model, specified via configuration, and provides a method to detect landmarks in images. It maps the detected landmark points to specific facial features based on a predefined mapping file. Attributes: source ( LandmarkerSource ) \u2013 The source identifier for the landmarker model used (e.g., MEDIAPIPE). landmarker_info ( ResourceMetadata ) \u2013 Metadata loaded from configuration about the landmarker model resource. model_path ( str ) \u2013 The local path to the downloaded landmarker model file. landmark_mapping ( Dict [ FacialFeature , List [ int ]] ) \u2013 A dictionary mapping facial features (enum) to lists of landmark indices provided by the MediaPipe model. detector ( FaceLandmarker ) \u2013 The initialized MediaPipe FaceLandmarker instance.","title":"FacialLandmarker"},{"location":"api/explainers/#biasx.explainers.FacialLandmarker.__init__","text":"Initialize the facial landmark detector. Loads resources based on the specified source, sets up the MediaPipe FaceLandmarker options, and creates the detector instance. Parameters: source ( LandmarkerSource ) \u2013 The source of the landmarker model to use (e.g., LandmarkerSource.MEDIAPIPE). Corresponds to keys in landmarker_config.json .","title":"__init__"},{"location":"api/explainers/#biasx.explainers.FacialLandmarker.detect","text":"Detect facial landmarks in one or more images. Takes a single PIL image or a list of PIL images, converts them into MediaPipe's Image format, and runs detection using the initialized landmarker. For each image where landmarks are detected, it converts the normalized landmark coordinates to pixel coordinates and groups them into bounding boxes based on the self.landmark_mapping for each facial feature. Parameters: images ( Union [ Image , List [ Image ]] ) \u2013 A single PIL image or a list of PIL images to process. Returns: List [ List [ Box ]] \u2013 A list of lists of Box objects. The outer list corresponds to the input images. Each inner list contains biasx.types.Box objects, one for each facial feature defined in the mapping, representing the bounding box encompassing the landmarks for that feature in the corresponding image. If no landmarks are detected in an image, its corresponding inner list will be empty.","title":"detect"},{"location":"api/explainers/#classactivationmapper","text":"","title":"ClassActivationMapper"},{"location":"api/explainers/#biasx.explainers.ClassActivationMapper","text":"Generates and processes class activation maps (CAMs). This class uses a specified CAM generation method (e.g., Grad-CAM++, Score-CAM) from the tf-keras-vis library to produce heatmaps highlighting regions important for a model's classification decision. It also provides methods to process these heatmaps by applying thresholding and identifying contiguous activated regions as bounding boxes. Attributes: cam_method ( ModelVisualization ) \u2013 The instantiated CAM visualization object (e.g., GradcamPlusPlus) based on the configured method. cutoff_percentile ( int ) \u2013 The percentile value (0-100) used to determine the threshold for filtering low-activation areas in the heatmap. threshold_method ( Callable [[ ndarray ], Any ] ) \u2013 The thresholding function (e.g., skimage.filters.threshold_otsu) used to binarize the filtered heatmap.","title":"ClassActivationMapper"},{"location":"api/explainers/#biasx.explainers.ClassActivationMapper.__init__","text":"Initialize the activation map generator and processor. Parameters: cam_method ( CAMMethod ) \u2013 The CAM algorithm to use (e.g., CAMMethod.GRADCAM_PLUS_PLUS). cutoff_percentile ( int ) \u2013 The percentile (0-100) to use for thresholding the raw heatmap. Activations below this percentile are zeroed out. threshold_method ( ThresholdMethod ) \u2013 The algorithm used to binarize the filtered heatmap (e.g., ThresholdMethod.OTSU).","title":"__init__"},{"location":"api/explainers/#biasx.explainers.ClassActivationMapper.generate_heatmap","text":"Generate class activation maps (heatmaps) for preprocessed images. Uses the configured CAM method ( tf-keras-vis ) to generate heatmaps for the given images with respect to the specified target classes. It handles preparing the images and defining the score function for the visualizer. Parameters: model ( Model ) \u2013 The trained Keras model to explain. preprocessed_images ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single preprocessed image (NumPy array) or a list/batch of preprocessed images (NumPy array). Assumes images are normalized and correctly shaped. target_classes ( Union [ Gender , List [ Gender ]] ) \u2013 The target class(es) (Gender enum) for which to generate the heatmaps. If a single Gender is provided, it's used for all images in the batch. Returns: List [ ndarray ] \u2013 A list of NumPy arrays, where each array is a 2D heatmap corresponding to an input image. Returns an empty list if the input is empty.","title":"generate_heatmap"},{"location":"api/explainers/#biasx.explainers.ClassActivationMapper.process_heatmap","text":"Process heatmaps into bounding boxes of activated regions. Takes raw heatmaps, applies a percentile cutoff threshold, binarizes the result using the configured thresholding method, identifies connected regions (blobs) in the binary map, and converts these regions into bounding boxes scaled to the original image dimensions. Parameters: heatmaps ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single 2D heatmap or a list of 2D heatmaps (NumPy arrays) as generated by generate_heatmap . pil_images ( List [ Image ] ) \u2013 A list of the original PIL images corresponding to the heatmaps, used to get dimensions for scaling. Must be the same length as the list of heatmaps. Returns: List [ List [ Box ]] \u2013 A list of lists of Box objects. The outer list corresponds to the input heatmaps/images. Each inner list contains biasx.types.Box objects representing the bounding boxes of activated regions found in the corresponding heatmap. Boxes do not have features assigned at this stage.","title":"process_heatmap"},{"location":"api/models/","text":"Models This module handles the loading and prediction using face classification models. biasx.models.Model Handles loading and inference for facial classification models. This class loads a Keras model from a specified path, handles batching and preprocessing of input images, performs inference, and processes the model's output probabilities into classified gender labels and confidence scores. It accounts for potentially inverted class labels. Attributes: model ( Model ) \u2013 The loaded Keras model instance. inverted_classes ( bool ) \u2013 If True, swaps the interpretation of the model's output classes (e.g., if the model outputs 0 for female and 1 for male, setting this to True maps 0 to MALE and 1 to FEMALE). batch_size ( int ) \u2013 The batch size to use during model prediction ( model.predict ). _metadata ( Any ) \u2013 Placeholder for potential future metadata storage. Currently initialized to None and not used. __init__ ( path , inverted_classes , batch_size , ** kwargs ) Initialize the classification model handler. Loads the Keras model from the given file path and stores configuration parameters. Parameters: path ( str ) \u2013 The file path to the saved Keras model (.h5 or SavedModel dir). inverted_classes ( bool ) \u2013 Whether the model's output classes (0 and 1) should be interpreted in reverse order compared to the Gender enum (MALE=0, FEMALE=1). batch_size ( int ) \u2013 The batch size to use when calling model.predict . **kwargs \u2013 Additional keyword arguments passed via configuration. predict ( preprocessed_images ) Make gender predictions from preprocessed images. This is the main public method for getting predictions. It orchestrates the process: Prepares the input images using _prepare_input . Gets raw probabilities from the model using _get_probabilities . Processes these probabilities into gender labels and confidences using _process_predictions . Parameters: preprocessed_images ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single preprocessed image, a list of images, or a batch of images (NumPy arrays). Returns: List [ Tuple [ Gender , float ]] \u2013 A list of tuples, one for each input image. Each tuple contains: - predicted_gender (biasx.types.Gender): The predicted gender. - confidence (float): The prediction confidence. List [ Tuple [ Gender , float ]] \u2013 Returns an empty list if the input is empty.","title":"Models"},{"location":"api/models/#models","text":"This module handles the loading and prediction using face classification models.","title":"Models"},{"location":"api/models/#biasx.models.Model","text":"Handles loading and inference for facial classification models. This class loads a Keras model from a specified path, handles batching and preprocessing of input images, performs inference, and processes the model's output probabilities into classified gender labels and confidence scores. It accounts for potentially inverted class labels. Attributes: model ( Model ) \u2013 The loaded Keras model instance. inverted_classes ( bool ) \u2013 If True, swaps the interpretation of the model's output classes (e.g., if the model outputs 0 for female and 1 for male, setting this to True maps 0 to MALE and 1 to FEMALE). batch_size ( int ) \u2013 The batch size to use during model prediction ( model.predict ). _metadata ( Any ) \u2013 Placeholder for potential future metadata storage. Currently initialized to None and not used.","title":"Model"},{"location":"api/models/#biasx.models.Model.__init__","text":"Initialize the classification model handler. Loads the Keras model from the given file path and stores configuration parameters. Parameters: path ( str ) \u2013 The file path to the saved Keras model (.h5 or SavedModel dir). inverted_classes ( bool ) \u2013 Whether the model's output classes (0 and 1) should be interpreted in reverse order compared to the Gender enum (MALE=0, FEMALE=1). batch_size ( int ) \u2013 The batch size to use when calling model.predict . **kwargs \u2013 Additional keyword arguments passed via configuration.","title":"__init__"},{"location":"api/models/#biasx.models.Model.predict","text":"Make gender predictions from preprocessed images. This is the main public method for getting predictions. It orchestrates the process: Prepares the input images using _prepare_input . Gets raw probabilities from the model using _get_probabilities . Processes these probabilities into gender labels and confidences using _process_predictions . Parameters: preprocessed_images ( Union [ ndarray , List [ ndarray ]] ) \u2013 A single preprocessed image, a list of images, or a batch of images (NumPy arrays). Returns: List [ Tuple [ Gender , float ]] \u2013 A list of tuples, one for each input image. Each tuple contains: - predicted_gender (biasx.types.Gender): The predicted gender. - confidence (float): The prediction confidence. List [ Tuple [ Gender , float ]] \u2013 Returns an empty list if the input is empty.","title":"predict"},{"location":"api/types/","text":"Data Types This module defines common enumerations and data structures used throughout the BiasX library. Enumerations biasx.types.Gender Bases: IntEnum Gender classification labels used in datasets and model outputs. Attributes: MALE \u2013 Represents the male gender, typically assigned the integer value 0. FEMALE \u2013 Represents the female gender, typically assigned the integer value 1. biasx.types.Age Bases: IntEnum Age range classification labels, often used in datasets like UTKFace. Attributes: RANGE_0_9 \u2013 Age range 0-9 years. RANGE_10_19 \u2013 Age range 10-19 years. RANGE_20_29 \u2013 Age range 20-29 years. RANGE_30_39 \u2013 Age range 30-39 years. RANGE_40_49 \u2013 Age range 40-49 years. RANGE_50_59 \u2013 Age range 50-59 years. RANGE_60_69 \u2013 Age range 60-69 years. RANGE_70_PLUS \u2013 Age range 70 years and above. biasx.types.Race Bases: IntEnum Race classification labels used in datasets. Attributes: WHITE \u2013 Represents the White race category. BLACK \u2013 Represents the Black race category. ASIAN \u2013 Represents the Asian race category. INDIAN \u2013 Represents the Indian race category. OTHER \u2013 Represents other race categories not listed. biasx.types.FacialFeature Bases: Enum Enumeration of facial features identifiable via landmark detection. Used to label landmark groups and potentially activation map regions. Attributes: LEFT_EYE \u2013 The region corresponding to the left eye. RIGHT_EYE \u2013 The region corresponding to the right eye. NOSE \u2013 The region corresponding to the nose. LIPS \u2013 The region corresponding to the lips. LEFT_CHEEK \u2013 The region corresponding to the left cheek. RIGHT_CHEEK \u2013 The region corresponding to the right cheek. CHIN \u2013 The region corresponding to the chin. FOREHEAD \u2013 The region corresponding to the forehead. LEFT_EYEBROW \u2013 The region corresponding to the left eyebrow. RIGHT_EYEBROW \u2013 The region corresponding to the right eyebrow. biasx.types.DatasetSource Bases: Enum Identifiers for supported dataset sources. Used in configuration to specify which dataset to load. Attributes: UTKFACE \u2013 Represents the UTKFace dataset. FAIRFACE \u2013 Represents the FairFace dataset. biasx.types.LandmarkerSource Bases: Enum Identifiers for supported facial landmark detection models/providers. Used in configuration to specify the landmarker implementation. Attributes: MEDIAPIPE \u2013 Represents the MediaPipe face landmarker model. biasx.types.ColorMode Bases: Enum Image color modes compatible with PIL (Pillow). Used in dataset configuration to specify target image format. Attributes: GRAYSCALE \u2013 Represents grayscale ('L' mode in PIL). RGB \u2013 Represents standard Red-Green-Blue color ('RGB' mode in PIL). biasx.types.CAMMethod Bases: Enum Supported Class Activation Mapping (CAM) methods. Used in configuration to select the algorithm for generating visual explanations (heatmaps). Attributes: GRADCAM \u2013 Represents the Grad-CAM algorithm. GRADCAM_PLUS_PLUS \u2013 Represents the Grad-CAM++ algorithm. SCORECAM \u2013 Represents the Score-CAM algorithm. get_implementation () Get the implementation class for this CAM method. biasx.types.ThresholdMethod Bases: Enum Supported thresholding methods for processing activation maps. Used in configuration to select the algorithm for binarizing heatmaps after initial percentile filtering. Relies on skimage.filters . Attributes: OTSU \u2013 Represents Otsu's thresholding method. SAUVOLA \u2013 Represents Sauvola's thresholding method (local). TRIANGLE \u2013 Represents the Triangle thresholding method. get_implementation () Get the corresponding implementation function from skimage.filters . Returns the specific thresholding function (e.g., threshold_otsu ) associated with the enum member. Returns: Callable [[ ndarray ], Any ] \u2013 The skimage.filters function implementing the selected method. biasx.types.DistanceMetric Bases: Enum Supported distance metrics for comparing spatial coordinates. Used in configuration to specify how the distance between activation box centers and landmark box centers is calculated. Values correspond to valid metrics for scipy.spatial.distance.cdist . Attributes: CITYBLOCK \u2013 Represents the Manhattan distance (L1 norm). COSINE \u2013 Represents the Cosine distance. EUCLIDEAN \u2013 Represents the standard Euclidean distance (L2 norm). Data Classes biasx.types.Box dataclass Represents a rectangular bounding box with an optional feature label. Used for both facial landmark features and activation map regions. Attributes: min_x ( int ) \u2013 The minimum x-coordinate (left edge) of the box. min_y ( int ) \u2013 The minimum y-coordinate (top edge) of the box. max_x ( int ) \u2013 The maximum x-coordinate (right edge) of the box. max_y ( int ) \u2013 The maximum y-coordinate (bottom edge) of the box. feature ( Optional [ FacialFeature ] ) \u2013 The facial feature associated with this box, if identified (e.g., FacialFeature.NOSE). Defaults to None. area property Compute area of the box. center property Compute center coordinates of the box. biasx.types.ResourceMetadata dataclass Metadata for a resource, typically downloaded from HuggingFace Hub. Used to store information about datasets and models defined in configuration files. Attributes: repo_id ( str ) \u2013 The repository ID on HuggingFace Hub (e.g., 'janko/utkface-dataset'). filename ( str ) \u2013 The specific filename within the repository (e.g., 'utkface_aligned_cropped.parquet'). repo_type ( str ) \u2013 The type of repository on HuggingFace Hub (e.g., 'dataset', 'model'). Defaults to 'dataset'. image_id_col ( str ) \u2013 The name of the column containing image identifiers in a dataset. Defaults to \"\". Relevant only for datasets. image_col ( str ) \u2013 The name of the column containing image data (e.g., bytes) in a dataset. Defaults to \"\". Relevant only for datasets. gender_col ( str ) \u2013 The name of the column containing gender labels in a dataset. Defaults to \"\". Relevant only for datasets. age_col ( str ) \u2013 The name of the column containing age labels in a dataset. Defaults to \"\". Relevant only for datasets. race_col ( str ) \u2013 The name of the column containing race labels in a dataset. Defaults to \"\". Relevant only for datasets. biasx.types.ImageData dataclass Container for data associated with a single image sample. Includes identifiers, raw and preprocessed image representations, dimensions, and demographic labels. Attributes: image_id ( str ) \u2013 A unique identifier for the image. pil_image ( Optional [ Image ] ) \u2013 The raw image loaded as a PIL object. Defaults to None. preprocessed_image ( Optional [ ndarray ] ) \u2013 The image after numerical preprocessing (e.g., resizing, normalization, type conversion), ready for model input. Defaults to None. width ( Optional [ int ] ) \u2013 The width of the preprocessed_image . Defaults to None. height ( Optional [ int ] ) \u2013 The height of the preprocessed_image . Defaults to None. gender ( Optional [ Gender ] ) \u2013 The ground truth gender label for the image. Defaults to None. age ( Optional [ Age ] ) \u2013 The ground truth age label for the image. Defaults to None. race ( Optional [ Race ] ) \u2013 The ground truth race label for the image. Defaults to None. biasx.types.Explanation dataclass Container for the analysis results and explanations for a single image. Combines the input image data with model predictions and visual explanation outputs (activation maps, boxes). Attributes: image_data ( ImageData ) \u2013 The original data associated with the image. predicted_gender ( Gender ) \u2013 The gender predicted by the model. prediction_confidence ( float ) \u2013 The model's confidence score for the prediction. activation_map ( ndarray ) \u2013 The raw 2D heatmap generated by the CAM method. activation_boxes ( List [ Box ] ) \u2013 Bounding boxes derived from the activation map. Boxes may have their feature attribute set if linked to a landmark. landmark_boxes ( List [ Box ] ) \u2013 Bounding boxes detected for facial landmarks, with their feature attribute set. biasx.types.FeatureAnalysis dataclass Container for bias analysis results specific to a single facial feature. Stores the calculated probability of a feature being activated during misclassifications for each gender group, and the resulting bias score. Attributes: feature ( FacialFeature ) \u2013 The facial feature being analyzed. bias_score ( float ) \u2013 The absolute difference between male_probability and female_probability . A measure of bias associated with this feature. male_probability ( float ) \u2013 The probability that this feature was activated in images where the true gender was male, but the model predicted incorrectly. female_probability ( float ) \u2013 The probability that this feature was activated in images where the true gender was female, but the model predicted incorrectly. biasx.types.DisparityScores dataclass Container for overall bias and fairness disparity metrics for the model. Aggregates results across features and performance metrics. Attributes: biasx ( float ) \u2013 An overall bias score, calculated as the average of the absolute bias_score values across all analyzed features in FeatureAnalysis . Defaults to 0.0. equalized_odds ( float ) \u2013 A fairness metric representing the maximum disparity between male and female groups in either the True Positive Rate (TPR) or the False Positive Rate (FPR). A score of 0 indicates perfect equality in these error rates. Defaults to 0.0. biasx.types.AnalysisResult dataclass Container for the complete results of a bias analysis run. Holds all generated explanations, feature-specific analyses, and overall disparity scores. Attributes: explanations ( List [ Explanation ] ) \u2013 A list containing an Explanation object for every image analyzed in the run. Defaults to an empty list. feature_analyses ( Dict [ FacialFeature , FeatureAnalysis ] ) \u2013 A dictionary mapping each analyzed FacialFeature to its corresponding FeatureAnalysis object. Defaults to an empty dictionary. disparity_scores ( DisparityScores ) \u2013 An object containing the calculated overall bias metrics ( biasx , equalized_odds ). Defaults to a DisparityScores object with default (0.0) values.","title":"Types"},{"location":"api/types/#data-types","text":"This module defines common enumerations and data structures used throughout the BiasX library.","title":"Data Types"},{"location":"api/types/#enumerations","text":"","title":"Enumerations"},{"location":"api/types/#biasx.types.Gender","text":"Bases: IntEnum Gender classification labels used in datasets and model outputs. Attributes: MALE \u2013 Represents the male gender, typically assigned the integer value 0. FEMALE \u2013 Represents the female gender, typically assigned the integer value 1.","title":"Gender"},{"location":"api/types/#biasx.types.Age","text":"Bases: IntEnum Age range classification labels, often used in datasets like UTKFace. Attributes: RANGE_0_9 \u2013 Age range 0-9 years. RANGE_10_19 \u2013 Age range 10-19 years. RANGE_20_29 \u2013 Age range 20-29 years. RANGE_30_39 \u2013 Age range 30-39 years. RANGE_40_49 \u2013 Age range 40-49 years. RANGE_50_59 \u2013 Age range 50-59 years. RANGE_60_69 \u2013 Age range 60-69 years. RANGE_70_PLUS \u2013 Age range 70 years and above.","title":"Age"},{"location":"api/types/#biasx.types.Race","text":"Bases: IntEnum Race classification labels used in datasets. Attributes: WHITE \u2013 Represents the White race category. BLACK \u2013 Represents the Black race category. ASIAN \u2013 Represents the Asian race category. INDIAN \u2013 Represents the Indian race category. OTHER \u2013 Represents other race categories not listed.","title":"Race"},{"location":"api/types/#biasx.types.FacialFeature","text":"Bases: Enum Enumeration of facial features identifiable via landmark detection. Used to label landmark groups and potentially activation map regions. Attributes: LEFT_EYE \u2013 The region corresponding to the left eye. RIGHT_EYE \u2013 The region corresponding to the right eye. NOSE \u2013 The region corresponding to the nose. LIPS \u2013 The region corresponding to the lips. LEFT_CHEEK \u2013 The region corresponding to the left cheek. RIGHT_CHEEK \u2013 The region corresponding to the right cheek. CHIN \u2013 The region corresponding to the chin. FOREHEAD \u2013 The region corresponding to the forehead. LEFT_EYEBROW \u2013 The region corresponding to the left eyebrow. RIGHT_EYEBROW \u2013 The region corresponding to the right eyebrow.","title":"FacialFeature"},{"location":"api/types/#biasx.types.DatasetSource","text":"Bases: Enum Identifiers for supported dataset sources. Used in configuration to specify which dataset to load. Attributes: UTKFACE \u2013 Represents the UTKFace dataset. FAIRFACE \u2013 Represents the FairFace dataset.","title":"DatasetSource"},{"location":"api/types/#biasx.types.LandmarkerSource","text":"Bases: Enum Identifiers for supported facial landmark detection models/providers. Used in configuration to specify the landmarker implementation. Attributes: MEDIAPIPE \u2013 Represents the MediaPipe face landmarker model.","title":"LandmarkerSource"},{"location":"api/types/#biasx.types.ColorMode","text":"Bases: Enum Image color modes compatible with PIL (Pillow). Used in dataset configuration to specify target image format. Attributes: GRAYSCALE \u2013 Represents grayscale ('L' mode in PIL). RGB \u2013 Represents standard Red-Green-Blue color ('RGB' mode in PIL).","title":"ColorMode"},{"location":"api/types/#biasx.types.CAMMethod","text":"Bases: Enum Supported Class Activation Mapping (CAM) methods. Used in configuration to select the algorithm for generating visual explanations (heatmaps). Attributes: GRADCAM \u2013 Represents the Grad-CAM algorithm. GRADCAM_PLUS_PLUS \u2013 Represents the Grad-CAM++ algorithm. SCORECAM \u2013 Represents the Score-CAM algorithm.","title":"CAMMethod"},{"location":"api/types/#biasx.types.CAMMethod.get_implementation","text":"Get the implementation class for this CAM method.","title":"get_implementation"},{"location":"api/types/#biasx.types.ThresholdMethod","text":"Bases: Enum Supported thresholding methods for processing activation maps. Used in configuration to select the algorithm for binarizing heatmaps after initial percentile filtering. Relies on skimage.filters . Attributes: OTSU \u2013 Represents Otsu's thresholding method. SAUVOLA \u2013 Represents Sauvola's thresholding method (local). TRIANGLE \u2013 Represents the Triangle thresholding method.","title":"ThresholdMethod"},{"location":"api/types/#biasx.types.ThresholdMethod.get_implementation","text":"Get the corresponding implementation function from skimage.filters . Returns the specific thresholding function (e.g., threshold_otsu ) associated with the enum member. Returns: Callable [[ ndarray ], Any ] \u2013 The skimage.filters function implementing the selected method.","title":"get_implementation"},{"location":"api/types/#biasx.types.DistanceMetric","text":"Bases: Enum Supported distance metrics for comparing spatial coordinates. Used in configuration to specify how the distance between activation box centers and landmark box centers is calculated. Values correspond to valid metrics for scipy.spatial.distance.cdist . Attributes: CITYBLOCK \u2013 Represents the Manhattan distance (L1 norm). COSINE \u2013 Represents the Cosine distance. EUCLIDEAN \u2013 Represents the standard Euclidean distance (L2 norm).","title":"DistanceMetric"},{"location":"api/types/#data-classes","text":"","title":"Data Classes"},{"location":"api/types/#biasx.types.Box","text":"Represents a rectangular bounding box with an optional feature label. Used for both facial landmark features and activation map regions. Attributes: min_x ( int ) \u2013 The minimum x-coordinate (left edge) of the box. min_y ( int ) \u2013 The minimum y-coordinate (top edge) of the box. max_x ( int ) \u2013 The maximum x-coordinate (right edge) of the box. max_y ( int ) \u2013 The maximum y-coordinate (bottom edge) of the box. feature ( Optional [ FacialFeature ] ) \u2013 The facial feature associated with this box, if identified (e.g., FacialFeature.NOSE). Defaults to None.","title":"Box"},{"location":"api/types/#biasx.types.Box.area","text":"Compute area of the box.","title":"area"},{"location":"api/types/#biasx.types.Box.center","text":"Compute center coordinates of the box.","title":"center"},{"location":"api/types/#biasx.types.ResourceMetadata","text":"Metadata for a resource, typically downloaded from HuggingFace Hub. Used to store information about datasets and models defined in configuration files. Attributes: repo_id ( str ) \u2013 The repository ID on HuggingFace Hub (e.g., 'janko/utkface-dataset'). filename ( str ) \u2013 The specific filename within the repository (e.g., 'utkface_aligned_cropped.parquet'). repo_type ( str ) \u2013 The type of repository on HuggingFace Hub (e.g., 'dataset', 'model'). Defaults to 'dataset'. image_id_col ( str ) \u2013 The name of the column containing image identifiers in a dataset. Defaults to \"\". Relevant only for datasets. image_col ( str ) \u2013 The name of the column containing image data (e.g., bytes) in a dataset. Defaults to \"\". Relevant only for datasets. gender_col ( str ) \u2013 The name of the column containing gender labels in a dataset. Defaults to \"\". Relevant only for datasets. age_col ( str ) \u2013 The name of the column containing age labels in a dataset. Defaults to \"\". Relevant only for datasets. race_col ( str ) \u2013 The name of the column containing race labels in a dataset. Defaults to \"\". Relevant only for datasets.","title":"ResourceMetadata"},{"location":"api/types/#biasx.types.ImageData","text":"Container for data associated with a single image sample. Includes identifiers, raw and preprocessed image representations, dimensions, and demographic labels. Attributes: image_id ( str ) \u2013 A unique identifier for the image. pil_image ( Optional [ Image ] ) \u2013 The raw image loaded as a PIL object. Defaults to None. preprocessed_image ( Optional [ ndarray ] ) \u2013 The image after numerical preprocessing (e.g., resizing, normalization, type conversion), ready for model input. Defaults to None. width ( Optional [ int ] ) \u2013 The width of the preprocessed_image . Defaults to None. height ( Optional [ int ] ) \u2013 The height of the preprocessed_image . Defaults to None. gender ( Optional [ Gender ] ) \u2013 The ground truth gender label for the image. Defaults to None. age ( Optional [ Age ] ) \u2013 The ground truth age label for the image. Defaults to None. race ( Optional [ Race ] ) \u2013 The ground truth race label for the image. Defaults to None.","title":"ImageData"},{"location":"api/types/#biasx.types.Explanation","text":"Container for the analysis results and explanations for a single image. Combines the input image data with model predictions and visual explanation outputs (activation maps, boxes). Attributes: image_data ( ImageData ) \u2013 The original data associated with the image. predicted_gender ( Gender ) \u2013 The gender predicted by the model. prediction_confidence ( float ) \u2013 The model's confidence score for the prediction. activation_map ( ndarray ) \u2013 The raw 2D heatmap generated by the CAM method. activation_boxes ( List [ Box ] ) \u2013 Bounding boxes derived from the activation map. Boxes may have their feature attribute set if linked to a landmark. landmark_boxes ( List [ Box ] ) \u2013 Bounding boxes detected for facial landmarks, with their feature attribute set.","title":"Explanation"},{"location":"api/types/#biasx.types.FeatureAnalysis","text":"Container for bias analysis results specific to a single facial feature. Stores the calculated probability of a feature being activated during misclassifications for each gender group, and the resulting bias score. Attributes: feature ( FacialFeature ) \u2013 The facial feature being analyzed. bias_score ( float ) \u2013 The absolute difference between male_probability and female_probability . A measure of bias associated with this feature. male_probability ( float ) \u2013 The probability that this feature was activated in images where the true gender was male, but the model predicted incorrectly. female_probability ( float ) \u2013 The probability that this feature was activated in images where the true gender was female, but the model predicted incorrectly.","title":"FeatureAnalysis"},{"location":"api/types/#biasx.types.DisparityScores","text":"Container for overall bias and fairness disparity metrics for the model. Aggregates results across features and performance metrics. Attributes: biasx ( float ) \u2013 An overall bias score, calculated as the average of the absolute bias_score values across all analyzed features in FeatureAnalysis . Defaults to 0.0. equalized_odds ( float ) \u2013 A fairness metric representing the maximum disparity between male and female groups in either the True Positive Rate (TPR) or the False Positive Rate (FPR). A score of 0 indicates perfect equality in these error rates. Defaults to 0.0.","title":"DisparityScores"},{"location":"api/types/#biasx.types.AnalysisResult","text":"Container for the complete results of a bias analysis run. Holds all generated explanations, feature-specific analyses, and overall disparity scores. Attributes: explanations ( List [ Explanation ] ) \u2013 A list containing an Explanation object for every image analyzed in the run. Defaults to an empty list. feature_analyses ( Dict [ FacialFeature , FeatureAnalysis ] ) \u2013 A dictionary mapping each analyzed FacialFeature to its corresponding FeatureAnalysis object. Defaults to an empty dictionary. disparity_scores ( DisparityScores ) \u2013 An object containing the calculated overall bias metrics ( biasx , equalized_odds ). Defaults to a DisparityScores object with default (0.0) values.","title":"AnalysisResult"},{"location":"api/utils/","text":"Utilities This module provides common utility functions used within the BiasX library. biasx . utils . get_json_config ( caller_file , config_file ) cached Load a JSON configuration file relative to the calling module's data directory. Constructs the path to the config file assuming it resides within a 'data' subdirectory relative to the Python file that calls this function. Uses LRU caching to avoid reloading the same configuration file multiple times. Parameters: caller_file ( str ) \u2013 The path to the Python file calling this function (typically __file__ from the caller). Used to determine the module's directory. config_file ( str ) \u2013 The name of the JSON configuration file (e.g., 'dataset_config.json'). Returns: Dict [ str , Any ] \u2013 A dictionary containing the parsed JSON configuration data. Raises: FileNotFoundError \u2013 If the constructed path to the configuration file does not exist. JSONDecodeError \u2013 If the file exists but is not valid JSON. biasx . utils . get_resource_path ( repo_id , filename , repo_type = 'dataset' , force_download = False ) cached Download or retrieve a cached resource file from HuggingFace Hub. Uses the huggingface_hub library to download a file from a specified repository. Manages caching in a standardized local directory structure within ~/.biasx/cache/ . Uses LRU caching on the function call itself to quickly return the path if requested again with the same arguments. Parameters: repo_id ( str ) \u2013 The HuggingFace Hub repository ID (e.g., 'google/mediapipe'). filename ( str ) \u2013 The name of the file to download from the repository. repo_type ( str , default: 'dataset' ) \u2013 The type of the repository (e.g., 'dataset', 'model', 'space'). Defaults to \"dataset\". force_download ( bool , default: False ) \u2013 If True, forces re-downloading the file even if it exists in the cache. Defaults to False. Returns: str \u2013 The local file path to the downloaded or cached resource. biasx . utils . get_cache_dir ( name ) Get or create a standardized cache directory path for persistent storage. Constructs a path within the user's home directory under .biasx/cache/ . Creates the directory (including parent directories) if it doesn't exist. Used by get_resource_path to determine where to store downloaded files. Parameters: name ( str ) \u2013 A specific name for the subdirectory within the cache (e.g., the repo_id with slashes replaced). Returns: Path \u2013 A pathlib.Path object representing the absolute path to the Path \u2013 specific cache subdirectory. biasx . utils . get_file_path ( caller_file , path ) Get the absolute path to a file relative to the calling module. Resolves a relative path based on the directory containing the Python file that calls this function. Checks if the resulting file path exists. Parameters: caller_file ( str ) \u2013 The path to the Python file calling this function (typically __file__ from the caller). path ( str ) \u2013 The relative path from the caller_file 's directory to the target file (e.g., 'data/landmark_mapping.json'). Returns: Path \u2013 A pathlib.Path object representing the absolute path to the target file. Raises: FileNotFoundError \u2013 If the resolved file path does not exist.","title":"Utilities"},{"location":"api/utils/#utilities","text":"This module provides common utility functions used within the BiasX library.","title":"Utilities"},{"location":"api/utils/#biasx.utils.get_json_config","text":"Load a JSON configuration file relative to the calling module's data directory. Constructs the path to the config file assuming it resides within a 'data' subdirectory relative to the Python file that calls this function. Uses LRU caching to avoid reloading the same configuration file multiple times. Parameters: caller_file ( str ) \u2013 The path to the Python file calling this function (typically __file__ from the caller). Used to determine the module's directory. config_file ( str ) \u2013 The name of the JSON configuration file (e.g., 'dataset_config.json'). Returns: Dict [ str , Any ] \u2013 A dictionary containing the parsed JSON configuration data. Raises: FileNotFoundError \u2013 If the constructed path to the configuration file does not exist. JSONDecodeError \u2013 If the file exists but is not valid JSON.","title":"get_json_config"},{"location":"api/utils/#biasx.utils.get_resource_path","text":"Download or retrieve a cached resource file from HuggingFace Hub. Uses the huggingface_hub library to download a file from a specified repository. Manages caching in a standardized local directory structure within ~/.biasx/cache/ . Uses LRU caching on the function call itself to quickly return the path if requested again with the same arguments. Parameters: repo_id ( str ) \u2013 The HuggingFace Hub repository ID (e.g., 'google/mediapipe'). filename ( str ) \u2013 The name of the file to download from the repository. repo_type ( str , default: 'dataset' ) \u2013 The type of the repository (e.g., 'dataset', 'model', 'space'). Defaults to \"dataset\". force_download ( bool , default: False ) \u2013 If True, forces re-downloading the file even if it exists in the cache. Defaults to False. Returns: str \u2013 The local file path to the downloaded or cached resource.","title":"get_resource_path"},{"location":"api/utils/#biasx.utils.get_cache_dir","text":"Get or create a standardized cache directory path for persistent storage. Constructs a path within the user's home directory under .biasx/cache/ . Creates the directory (including parent directories) if it doesn't exist. Used by get_resource_path to determine where to store downloaded files. Parameters: name ( str ) \u2013 A specific name for the subdirectory within the cache (e.g., the repo_id with slashes replaced). Returns: Path \u2013 A pathlib.Path object representing the absolute path to the Path \u2013 specific cache subdirectory.","title":"get_cache_dir"},{"location":"api/utils/#biasx.utils.get_file_path","text":"Get the absolute path to a file relative to the calling module. Resolves a relative path based on the directory containing the Python file that calls this function. Checks if the resulting file path exists. Parameters: caller_file ( str ) \u2013 The path to the Python file calling this function (typically __file__ from the caller). path ( str ) \u2013 The relative path from the caller_file 's directory to the target file (e.g., 'data/landmark_mapping.json'). Returns: Path \u2013 A pathlib.Path object representing the absolute path to the target file. Raises: FileNotFoundError \u2013 If the resolved file path does not exist.","title":"get_file_path"}]}
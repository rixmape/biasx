{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ozBQGhtZ5k"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YBF1Ovq0yjvp",
        "outputId": "e57f0591-61be-4d9a-efe0-67ac42e441c2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_utkface_dataset(\n",
        "    dataset_path: str,\n",
        "    n: int = -1,\n",
        "    seed: int = 42,\n",
        ") -> pd.DataFrame:\n",
        "    paths = np.array([os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(\".jpg\")])\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(paths)\n",
        "\n",
        "    if n > 0:\n",
        "        paths = paths[:n]\n",
        "\n",
        "    data = []\n",
        "    for path in paths:\n",
        "        filename = os.path.basename(path).split(\".\")[0]\n",
        "        try:\n",
        "            age, gender, *_ = filename.split(\"_\")\n",
        "            data.append([path, int(age), int(gender)])\n",
        "        except ValueError:\n",
        "            print(f\"Invalid filename: {filename}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"path\", \"age\", \"gender\"])\n",
        "\n",
        "\n",
        "df = load_utkface_dataset(\"../images/utkface\", n=1000)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "bY6cVWiWyjvq",
        "outputId": "7657bcea-971b-47a6-a2b5-7cab29d4cc1e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_label_distributions(df: pd.DataFrame):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
        "\n",
        "    sns.histplot(df, x=\"age\", ax=axes[0])\n",
        "    axes[0].set_xlabel(\"Age\")\n",
        "    axes[0].set_ylabel(\"\")\n",
        "\n",
        "    sns.countplot(df, x=\"gender\", ax=axes[1])\n",
        "    axes[1].set_xlabel(\"Gender\")\n",
        "    axes[1].set_ylabel(\"\")\n",
        "\n",
        "    fig.suptitle(f\"Class Distributions (n={len(df)})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_label_distributions(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "6OY5yVqhyjvq",
        "outputId": "bb64df20-cb26-45e5-cd0e-9425eac3410c"
      },
      "outputs": [],
      "source": [
        "df[\"age_group\"] = pd.cut(df[\"age\"], bins=range(0, 121, 20), labels=range(0, 120, 20), right=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "skzoBFrQtZ5m",
        "outputId": "b8a76fb6-4ea6-4d34-ec6d-9f5d7e2f134b"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "def resample_dataset(\n",
        "    dataset: pd.DataFrame,\n",
        "    sampler_class,\n",
        "    label_cols: list = [\"age_group\", \"gender\"],\n",
        "    seed: int = 42,\n",
        ") -> pd.DataFrame:\n",
        "    combined_target = dataset[label_cols].astype(str).agg(\"_\".join, axis=1)\n",
        "    sampler = sampler_class(random_state=seed)\n",
        "    X_res, _ = sampler.fit_resample(dataset, combined_target)\n",
        "    return X_res\n",
        "\n",
        "\n",
        "balanced_data = resample_dataset(df, RandomUnderSampler)\n",
        "plot_label_distributions(balanced_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "dFGo7bw0tZ5m",
        "outputId": "b2276f67-d8a5-4de9-e3e5-166783a449c2"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "def load_image_array(path, color_mode=\"L\", target_size=(96, 96)):\n",
        "    with open(path, \"rb\") as f:\n",
        "        image = Image.open(io.BytesIO(f.read()))\n",
        "        image = image.convert(color_mode).resize(target_size)\n",
        "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
        "        if color_mode == \"L\":\n",
        "            image_array = np.stack([image_array] * 3, axis=-1)\n",
        "    return image_array\n",
        "\n",
        "\n",
        "balanced_data.loc[:, \"image\"] = balanced_data[\"path\"].progress_apply(load_image_array)\n",
        "balanced_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "VZ5S0Pusyjvr",
        "outputId": "8c677cee-7093-4964-e1b1-6a63c0917c0c"
      },
      "outputs": [],
      "source": [
        "def display_images(\n",
        "    df: pd.DataFrame,\n",
        "    rows: int,\n",
        "    cols: int,\n",
        "    seed: int = 42,\n",
        "    image_col: str = \"image\",\n",
        "):\n",
        "    n_images = rows * cols\n",
        "    sample_df = df.sample(n=n_images, random_state=seed)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
        "    axes_flat = axes.flatten() if n_images > 1 else [axes]\n",
        "\n",
        "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
        "        if idx >= n_images:\n",
        "            break\n",
        "\n",
        "        axes_flat[idx].imshow(row[image_col], cmap=\"gray\")\n",
        "        axes_flat[idx].axis(\"off\")\n",
        "\n",
        "    for idx in range(len(sample_df), len(axes_flat)):\n",
        "        axes_flat[idx].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_images(balanced_data, 3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPLVUYSDtZ5o"
      },
      "outputs": [],
      "source": [
        "from keras.api.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def split_data(\n",
        "    df: pd.DataFrame,\n",
        "    image_col: str = \"image\",\n",
        "    label_col: str = \"gender\",\n",
        "    test_size: float = 0.1,\n",
        "    validation_size: float = 0.3,\n",
        "    seed: int = 42,\n",
        ") -> tuple:\n",
        "    images = np.stack(df[image_col].values)\n",
        "    labels = df[label_col].values\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        images,\n",
        "        labels,\n",
        "        test_size=test_size,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp,\n",
        "        y_temp,\n",
        "        test_size=validation_size,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    y_train = to_categorical(y_train, num_classes=2)\n",
        "    y_val = to_categorical(y_val, num_classes=2)\n",
        "    y_test = to_categorical(y_test, num_classes=2)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(balanced_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a77xUdH6tZ5q"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n69MvPJUyjvs"
      },
      "outputs": [],
      "source": [
        "from keras.api.layers import Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
        "from keras.api.models import Model\n",
        "from keras.api.optimizers import Adam\n",
        "from keras.api.regularizers import l2\n",
        "\n",
        "\n",
        "def build_model(hp, arch):\n",
        "    base_model = arch(weights=\"imagenet\", include_top=False, input_shape=(96, 96, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "    dense_unit = hp.Int(\"dense_unit\", min_value=256, max_value=512, step=64)\n",
        "    x = Dense(dense_unit, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.4, max_value=0.6, step=0.1)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    output = Dense(2, activation=\"softmax\")(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    learning_rate = hp.Choice(\"learning_rate\", values=[1e-4, 5e-4, 1e-3])\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QYK7zihJ9sL",
        "outputId": "854ff9f2-d9c1-4d11-f3b4-0a290ea6cf3e"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "from keras.api.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "def find_best_hyperparameters(\n",
        "    arch,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    epochs: int = 10,\n",
        "    batch_size: int = 32,\n",
        "):\n",
        "    log_dir = os.path.join(\"logs\", arch.__name__.lower())\n",
        "    model_dir = os.path.join(log_dir, f\"{arch.__name__.lower()}_best_model.h5\")\n",
        "\n",
        "    tuner = kt.Hyperband(\n",
        "        lambda x: build_model(x, arch),\n",
        "        objective=\"val_accuracy\",\n",
        "        overwrite=True,\n",
        "        directory=log_dir,\n",
        "        project_name=\"history\",\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "        ModelCheckpoint(model_dir, monitor=\"val_accuracy\", save_best_only=True, verbose=1, mode=\"max\"),\n",
        "    ]\n",
        "\n",
        "    tuner.search(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "\n",
        "    return tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "\n",
        "def tune_architectures(archs):\n",
        "    best_hps = {}\n",
        "    for arch in archs:\n",
        "        best_hps[arch.__name__] = find_best_hyperparameters(arch, X_train, y_train, X_val, y_val)\n",
        "    return best_hps\n",
        "\n",
        "\n",
        "architectures = [\n",
        "    keras.applications.ResNet50V2,\n",
        "    keras.applications.ResNet101V2,\n",
        "    keras.applications.ResNet152V2,\n",
        "    keras.applications.VGG16,\n",
        "    keras.applications.VGG19,\n",
        "    keras.applications.InceptionV3,\n",
        "    keras.applications.InceptionResNetV2,\n",
        "    keras.applications.Xception,\n",
        "]\n",
        "\n",
        "best_hps = tune_architectures(architectures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot the best hyperparameters for each architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNOQkETSQEkr"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate each model using the test set"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def initialize_model(model_path: str) -> keras.Model:\n",
    "    model = load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initialize_model(\"../tmp/identiface.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess facial image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_utkface_dataset(\n",
    "    dataset_path: str,\n",
    "    n: int = -1,\n",
    "    seed: int = 42,\n",
    "    gender_map: dict = {0: \"MALE\", 1: \"FEMALE\"},\n",
    ") -> pd.DataFrame:\n",
    "    try:\n",
    "        paths = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(\".jpg\")]\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(paths)\n",
    "\n",
    "        if n > 0:\n",
    "            paths = paths[:n]\n",
    "\n",
    "        data = []\n",
    "        for path in paths:\n",
    "            try:\n",
    "                filename = os.path.basename(path).split(\".\")[0]\n",
    "                _, gender, *_ = filename.split(\"_\")\n",
    "                gender_val = int(gender)\n",
    "                if gender_map:\n",
    "                    gender_val = gender_map.get(gender_val, gender_val)\n",
    "                data.append([path, gender_val])\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "        return pd.DataFrame(data, columns=[\"imagePath\", \"trueGender\"])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load dataset from {dataset_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "df = load_utkface_dataset(\"../images/utkface\", n=200)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def load_image_array(\n",
    "    path: str,\n",
    "    color_mode: str = \"L\",\n",
    "    target_size: tuple[int, int] = (48, 48),\n",
    "    expand_dims: bool = True,\n",
    ") -> np.ndarray:\n",
    "    try:\n",
    "        with Image.open(path) as image:\n",
    "            image = image.convert(color_mode).resize(target_size)\n",
    "            image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "\n",
    "            if color_mode == \"L\" and expand_dims:\n",
    "                image_array = np.stack([image_array] * 3, axis=-1)\n",
    "\n",
    "            return image_array\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load image {path}: {str(e)}\")\n",
    "\n",
    "\n",
    "df.loc[:, \"imageArray\"] = df[\"imagePath\"].progress_apply(\n",
    "    load_image_array,\n",
    "    expand_dims=False,  # Identiface model expects single-channel images\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    df: pd.DataFrame,\n",
    "    rows: int = 3,\n",
    "    cols: int = 5,\n",
    "    seed: int = 42,\n",
    "    image_col: str = \"imageArray\",\n",
    "    heatmap_col: str = None,\n",
    "):\n",
    "    n_images = rows * cols\n",
    "    sample_df = df.sample(n=n_images, random_state=seed)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes_flat = axes.flatten() if n_images > 1 else [axes]\n",
    "\n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        if idx >= n_images:\n",
    "            break\n",
    "\n",
    "        axes_flat[idx].imshow(row[image_col], cmap=\"gray\")\n",
    "        if heatmap_col and row[heatmap_col] is not None:\n",
    "            axes_flat[idx].imshow(row[heatmap_col], cmap=\"jet\", alpha=0.5)\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    for idx in range(len(sample_df), len(axes_flat)):\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_images(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify facial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(\n",
    "    model: keras.Model,\n",
    "    image: np.ndarray,\n",
    "    gender_map: dict = {0: \"MALE\", 1: \"FEMALE\"},\n",
    ") -> int:\n",
    "    try:\n",
    "        prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)\n",
    "        pred_class = np.argmax(prediction, axis=1)[0]\n",
    "        return gender_map.get(pred_class, pred_class) if gender_map else pred_class\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Prediction failed: {str(e)}\")\n",
    "\n",
    "\n",
    "df[\"predictedGender\"] = df[\"imageArray\"].progress_apply(\n",
    "    lambda x: predict_gender(\n",
    "        model,\n",
    "        x,\n",
    "        {0: \"FEMALE\", 1: \"MALE\"},  # Identiface model predicts opposite\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    data: pd.DataFrame,\n",
    "    true_col: str = \"trueGender\",\n",
    "    predicted_col: str = \"predictedGender\",\n",
    "    gender_map: dict = {0: \"MALE\", 1: \"FEMALE\"},\n",
    "):\n",
    "    labels = [gender_map[i] for i in sorted(gender_map.keys())]\n",
    "    cm = confusion_matrix(data[true_col], data[predicted_col])\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "\n",
    "    plt.title(\"Confusion Matrix of Gender Classification\")\n",
    "    plt.xlabel(\"Predicted Gender\")\n",
    "    plt.ylabel(\"Actual Gender\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate class activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_keras_vis\n",
    "import tf_keras_vis.gradcam\n",
    "import tf_keras_vis.scorecam\n",
    "\n",
    "\n",
    "def generate_heatmap(\n",
    "    model: keras.Model,\n",
    "    image: np.ndarray,\n",
    "    target_class: int,\n",
    "    method: str = \"gradcam++\",\n",
    "    gender_map: dict = {0: \"MALE\", 1: \"FEMALE\"},\n",
    "    penultimate_layer: int = -1,\n",
    ") -> np.ndarray:\n",
    "    def model_modifier(cloned_model: tf.keras.Model) -> None:\n",
    "        cloned_model.layers[penultimate_layer].activation = tf.keras.activations.linear\n",
    "\n",
    "    def score_function(output: tf.Tensor) -> tf.Tensor:\n",
    "        class_key = [k for k, v in gender_map.items() if v == target_class][0]\n",
    "        return output[0][class_key]\n",
    "\n",
    "    supported_methods = {\n",
    "        \"gradcam\": tf_keras_vis.gradcam.Gradcam,\n",
    "        \"gradcam++\": tf_keras_vis.gradcam.GradcamPlusPlus,\n",
    "        \"scorecam\": tf_keras_vis.scorecam.Scorecam,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        visualizer_class = supported_methods.get(method.lower())\n",
    "        if not visualizer_class:\n",
    "            raise ValueError(f\"Unsupported method: {method}. Choose from {list(supported_methods.keys())}\")\n",
    "        visualizer = visualizer_class(model, model_modifier=model_modifier, clone=True)\n",
    "\n",
    "        X = image if image.ndim == 3 else image[..., np.newaxis]  # Ensure image has channel dimension\n",
    "\n",
    "        return visualizer(score_function, X, penultimate_layer=penultimate_layer)[0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate heatmap: {str(e)}\")\n",
    "        return np.zeros_like(image)\n",
    "\n",
    "\n",
    "df[\"activation\"] = df.progress_apply(\n",
    "    lambda row: generate_heatmap(model=model, image=row[\"imageArray\"], target_class=row[\"trueGender\"]),\n",
    "    axis=1,\n",
    ")\n",
    "display_images(df, heatmap_col=\"activation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "\n",
    "def binarize_heatmap(\n",
    "    heatmap: np.ndarray,\n",
    "    top_percentile: int = 90,\n",
    "    method: str = \"otsu\",\n",
    ") -> np.ndarray:\n",
    "    threshold_value = np.percentile(heatmap, top_percentile)\n",
    "    heatmap[heatmap < threshold_value] = 0\n",
    "\n",
    "    supported_methods = {\n",
    "        \"otsu\": skimage.filters.threshold_otsu,\n",
    "        \"li\": skimage.filters.threshold_li,\n",
    "        \"yen\": skimage.filters.threshold_yen,\n",
    "    }\n",
    "\n",
    "    threshold_func = supported_methods.get(method)\n",
    "    if not threshold_func:\n",
    "        raise ValueError(f\"Unsupported method: {method}. Choose from {list(supported_methods.keys())}\")\n",
    "\n",
    "    threshold_value = threshold_func(heatmap)\n",
    "    return heatmap > threshold_value\n",
    "\n",
    "\n",
    "df.loc[:, \"activationBinary\"] = df[\"activation\"].progress_apply(binarize_heatmap)\n",
    "display_images(df, 10, 10, heatmap_col=\"activationBinary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate activation boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "\n",
    "def get_boxes(heatmap: np.ndarray) -> list[dict[str, int]]:\n",
    "    labeled_heatmap = label(heatmap)\n",
    "    regions = regionprops(labeled_heatmap)\n",
    "\n",
    "    boxes = []\n",
    "    for region in regions:\n",
    "        min_row, min_col, max_row, max_col = region.bbox\n",
    "        boxes.append({\"min_x\": min_col, \"min_y\": min_row, \"max_x\": max_col, \"max_y\": max_row, \"label\": None})\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "df.loc[:, \"activationBox\"] = df[\"activationBinary\"].progress_apply(get_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def display_images_with_boxes(\n",
    "    df: pd.DataFrame,\n",
    "    rows: int = 3,\n",
    "    cols: int = 5,\n",
    "    seed: int = 42,\n",
    "    image_col: str = \"imageArray\",\n",
    "    box_col: str = \"activationBox\",\n",
    ") -> None:\n",
    "    n_images = rows * cols\n",
    "    sample_df = df.sample(n=n_images, random_state=seed)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes_flat = axes.flatten() if n_images > 1 else [axes]\n",
    "\n",
    "    region_colors = {\n",
    "        \"left_eye\": (0, 0, 1),\n",
    "        \"right_eye\": (0, 1, 0),\n",
    "        \"nose\": (1, 0, 0),\n",
    "        \"lips\": (1, 1, 0),\n",
    "        \"left_cheek\": (1, 0, 1),\n",
    "        \"right_cheek\": (0, 1, 1),\n",
    "        \"left_eyebrow\": (0.5, 0.5, 0.5),\n",
    "        \"right_eyebrow\": (0.5, 0, 0.5),\n",
    "    }\n",
    "\n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        if idx >= n_images:\n",
    "            break\n",
    "\n",
    "        image = row[image_col].copy()\n",
    "        image = image if len(image.shape) == 3 else cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Ensure RGB image\n",
    "\n",
    "        for box in row[box_col]:\n",
    "            min_x, min_y, max_x, max_y, label = box.values()\n",
    "            cv2.rectangle(image, (min_x, min_y), (max_x, max_y), region_colors[label] if label else (1, 0, 0), 1)\n",
    "\n",
    "        axes_flat[idx].imshow(image, cmap=\"gray\")\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    for idx in range(len(sample_df), len(axes_flat)):\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_images_with_boxes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe\n",
    "from mediapipe.tasks.python.core.base_options import BaseOptions\n",
    "from mediapipe.tasks.python.vision.face_landmarker import FaceLandmarker, FaceLandmarkerOptions\n",
    "\n",
    "\n",
    "base_options = BaseOptions(model_asset_path=\"../tmp/mediapipe_landmarker.task\")\n",
    "options = FaceLandmarkerOptions(base_options=base_options, num_faces=1)\n",
    "detector = FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "def detect_landmark_points(\n",
    "    image_path: str,\n",
    "    detector=None,\n",
    "    scale: int = 1,\n",
    ") -> list[tuple[int, int]]:\n",
    "\n",
    "    image = mediapipe.Image.create_from_file(str(image_path))\n",
    "    detection_result = detector.detect(image)\n",
    "    faces = detection_result.face_landmarks\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected for {image_path}\")\n",
    "        return []\n",
    "\n",
    "    return [(int(round(landmark.x * scale)), int(round(landmark.y * scale))) for landmark in faces[0]]\n",
    "\n",
    "\n",
    "df.loc[:, \"landmarkPoint\"] = df[\"imagePath\"].progress_apply(\n",
    "    detect_landmark_points,\n",
    "    scale=48,\n",
    "    detector=detector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt:off\n",
    "landmark_map = {\n",
    "    \"left_eye\": [249, 263, 362, 373, 374, 380, 381, 382, 384, 385, 386, 387, 388, 390, 398, 466],\n",
    "    \"right_eye\": [7, 33, 133, 144, 145, 153, 154, 155, 157, 158, 159, 160, 161, 163, 173, 246],\n",
    "    \"nose\": [1, 2, 4, 5, 6, 19, 45, 48, 64, 94, 97, 98, 115, 168, 195, 197, 220, 275, 278, 294, 326, 327, 344, 440],\n",
    "    \"lips\": [0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415],\n",
    "    \"left_cheek\": [454, 447, 345, 346, 347, 330, 425, 427, 434, 416, 435, 288, 361, 323, 280, 352, 366, 411, 376, 401, 433],\n",
    "    \"right_cheek\": [234, 227, 116,117,118, 101, 205, 207, 214, 192, 215, 58, 132, 93, 127, 50, 123, 137, 177, 147, 187, 213],\n",
    "    \"left_eyebrow\": [276, 282, 283, 285, 293, 295, 296, 300, 334, 336],\n",
    "    \"right_eyebrow\": [46, 52, 53, 55, 63, 65, 66, 70, 105, 107],\n",
    "}\n",
    "# fmt:on\n",
    "\n",
    "def get_landmark_boxes(\n",
    "    points: list[tuple[int, int]],\n",
    "    landmark_map: dict[str, list[int]],\n",
    ") -> list[dict[str, int]]:\n",
    "\n",
    "    if not points:\n",
    "        return []\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for landmark, indices in landmark_map.items():\n",
    "        x_coords, y_coords = zip(*[points[idx] for idx in indices])\n",
    "        min_x, min_y = min(x_coords), min(y_coords)\n",
    "        max_x, max_y = max(x_coords), max(y_coords)\n",
    "        boxes.append({\"min_x\": min_x, \"min_y\": min_y, \"max_x\": max_x, \"max_y\": max_y, \"label\": landmark})\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "df.loc[:, \"landmarkBox\"] = df[\"landmarkPoint\"].progress_apply(get_landmark_boxes, landmark_map=landmark_map)\n",
    "display_images_with_boxes(df, box_col=\"landmarkBox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find nearest landmarks to activation boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_activation_boxes(\n",
    "    activation_boxes: list[dict[str, int]],\n",
    "    landmark_boxes: list[dict[str, int]],\n",
    ") -> list[dict[str, int]]:\n",
    "    if not landmark_boxes or not activation_boxes:\n",
    "        return []\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for a_box in activation_boxes:\n",
    "        nearest_l_box = min(landmark_boxes, key=lambda l_box: compute_euclidean_distance(a_box, l_box))\n",
    "\n",
    "        if has_significant_overlap(a_box, nearest_l_box, 0.2):\n",
    "            a_box[\"label\"] = nearest_l_box[\"label\"]\n",
    "            boxes.append(nearest_l_box)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# TODO: Use `scipy.spatial.distance.cdist` to compute pairwise distances between activation and landmark boxes\n",
    "# TODO: Set distance metric as a parameter to the function\n",
    "def compute_euclidean_distance(\n",
    "    activation_box: dict[str, int],\n",
    "    landmark_box: dict[str, int],\n",
    ") -> float:\n",
    "    x1 = (activation_box[\"min_x\"] + activation_box[\"max_x\"]) // 2\n",
    "    y1 = (activation_box[\"min_y\"] + activation_box[\"max_y\"]) // 2\n",
    "    x2 = (landmark_box[\"min_x\"] + landmark_box[\"max_x\"]) // 2\n",
    "    y2 = (landmark_box[\"min_y\"] + landmark_box[\"max_y\"]) // 2\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "\n",
    "def has_significant_overlap(\n",
    "    activation_box: dict[str, int],\n",
    "    landmark_box: dict[str, int],\n",
    "    percentage: float = 0.5,\n",
    ") -> bool:\n",
    "    # Calculate the intersection area\n",
    "    x_left = max(activation_box[\"min_x\"], landmark_box[\"min_x\"])\n",
    "    y_top = max(activation_box[\"min_y\"], landmark_box[\"min_y\"])\n",
    "    x_right = min(activation_box[\"max_x\"], landmark_box[\"max_x\"])\n",
    "    y_bottom = min(activation_box[\"max_y\"], landmark_box[\"max_y\"])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return False\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate the areas of the activation and landmark boxes\n",
    "    activation_area = (activation_box[\"max_x\"] - activation_box[\"min_x\"]) * (\n",
    "        activation_box[\"max_y\"] - activation_box[\"min_y\"]\n",
    "    )\n",
    "    landmark_area = (landmark_box[\"max_x\"] - landmark_box[\"min_x\"]) * (landmark_box[\"max_y\"] - landmark_box[\"min_y\"])\n",
    "\n",
    "    # Calculate the overlap percentage\n",
    "    overlap_percentage = intersection_area / float(activation_area)\n",
    "\n",
    "    return overlap_percentage >= percentage\n",
    "\n",
    "\n",
    "df.loc[:, \"annotatedBox\"] = df.progress_apply(\n",
    "    lambda row: annotate_activation_boxes(row[\"activationBox\"], row[\"landmarkBox\"]),\n",
    "    axis=1,\n",
    ")\n",
    "display_images_with_boxes(df, box_col=\"annotatedBox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def encode_facial_regions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([list(landmark_map.keys())])\n",
    "    df.loc[:, \"label\"] = df[\"annotatedBox\"].apply(lambda boxes: [box[\"label\"] for box in boxes])\n",
    "    label_columns = df[\"label\"].apply(lambda x: pd.Series([1 if label in x else 0 for label in mlb.classes_]))\n",
    "    label_columns.columns = mlb.classes_\n",
    "    return pd.concat([df, label_columns], axis=1)\n",
    "\n",
    "\n",
    "df = encode_facial_regions(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute equalized odds score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equalized_odds_score(\n",
    "    data: pd.DataFrame,\n",
    "    protected_col: str = \"trueGender\",\n",
    "    true_col: str = \"trueGender\",\n",
    "    pred_col: str = \"predictedGender\",\n",
    ") -> float:\n",
    "    gender_values = data[protected_col].unique().tolist()\n",
    "\n",
    "    tpr: dict[str, float] = {}\n",
    "    fpr: dict[str, float] = {}\n",
    "\n",
    "    for gender in gender_values:\n",
    "        group = data[data[protected_col] == gender]\n",
    "\n",
    "        # Calculate true positive rate\n",
    "        pos = group[group[true_col] == gender]\n",
    "        if len(pos) > 0:\n",
    "            tpr[gender] = len(pos[pos[pred_col] == gender]) / len(pos)\n",
    "        else:\n",
    "            tpr[gender] = 0.0\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        neg = group[group[true_col] != gender]\n",
    "        if len(neg) > 0:\n",
    "            fpr[gender] = len(neg[neg[pred_col] == gender]) / len(neg)\n",
    "        else:\n",
    "            fpr[gender] = 0.0\n",
    "\n",
    "    # Compare rates between gender groups\n",
    "    tpr_diff = abs(tpr[gender_values[0]] - tpr[gender_values[1]])\n",
    "    fpr_diff = abs(fpr[gender_values[0]] - fpr[gender_values[1]])\n",
    "\n",
    "    return max(tpr_diff, fpr_diff)\n",
    "\n",
    "\n",
    "equalized_odds_score = compute_equalized_odds_score(df)\n",
    "equalized_odds_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute feature probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_probabilities(\n",
    "    data: pd.DataFrame,\n",
    "    feature: str,\n",
    "    protected_col: str = \"trueGender\",\n",
    "    true_col: str = \"trueGender\",\n",
    "    pred_col: str = \"predictedGender\",\n",
    ") -> dict[int, float]:\n",
    "    gender_values = data[protected_col].unique().tolist()\n",
    "    probabilities: dict[str, float] = {}\n",
    "\n",
    "    for gender in gender_values:\n",
    "        # Get misclassified cases for this gender\n",
    "        misclassified = data[(data[protected_col] == gender) & (data[pred_col] != data[true_col])]\n",
    "\n",
    "        total_cases = len(misclassified)\n",
    "        if total_cases > 0:\n",
    "            feature_present = misclassified[misclassified[feature] == 1].shape[0]\n",
    "            probabilities[gender] = round(feature_present / total_cases, 3)\n",
    "        else:\n",
    "            probabilities[gender] = 0.0\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "feature_probabilities = {feature: compute_feature_probabilities(df, feature) for feature in landmark_map.keys()}\n",
    "feature_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute feature specific bias scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_bias_scores(\n",
    "    data: pd.DataFrame,\n",
    "    feature: str,\n",
    "    protected_col: str = \"trueGender\",\n",
    "    true_col: str = \"trueGender\",\n",
    "    pred_col: str = \"predictedGender\",\n",
    ") -> float:\n",
    "    gender_values = data[protected_col].unique().tolist()\n",
    "    probs = compute_feature_probabilities(data, feature, protected_col, true_col, pred_col)\n",
    "    return round(abs(probs[gender_values[0]] - probs[gender_values[1]]), 3)\n",
    "\n",
    "\n",
    "feature_bias_scores = {feature: compute_feature_bias_scores(df, feature) for feature in landmark_map}\n",
    "feature_bias_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute overall bias score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_bias_score(\n",
    "    data: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    protected_col: str = \"trueGender\",\n",
    "    true_col: str = \"trueGender\",\n",
    "    pred_col: str = \"predictedGender\",\n",
    ") -> float:\n",
    "    gender_values = data[protected_col].unique().tolist()\n",
    "    bias_scores = [\n",
    "        compute_feature_bias_scores(data, feature, protected_col, true_col, pred_col)\n",
    "        for feature in features\n",
    "    ]\n",
    "    return round(np.mean(bias_scores) if bias_scores else 0.0, 3)\n",
    "\n",
    "\n",
    "overall_bias_score = compute_overall_bias_score(df, list(landmark_map.keys()))\n",
    "overall_bias_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

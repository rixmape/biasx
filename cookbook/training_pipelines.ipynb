{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identiface pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def download_dataset(n: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Download facial image dataset from HuggingFace.\"\"\"\n",
    "    filepath = hf_hub_download(repo_id=\"rixmape/utkface\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=42) if n > 0 else df\n",
    "\n",
    "\n",
    "def prepare_data(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Process images and prepare training data.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        with Image.open(BytesIO(row[\"image\"][\"bytes\"])) as img:\n",
    "            img = img.convert(\"L\").resize((48, 48))\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "            img_array = img_array.reshape(48, 48, 1)\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(row[\"gender\"])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def build_vgg16() -> tf.keras.Sequential:\n",
    "    \"\"\"Build VGG16-like architecture using Sequential API.\"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(48, 48, 1), name=\"block1_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block1_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block2_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block3_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block4_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block5_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Sequential, X: np.ndarray, y: np.ndarray) -> tf.keras.Sequential:\n",
    "    \"\"\"Train model with class balancing and early stopping.\"\"\"\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total = len(y_train)\n",
    "    class_weights = {i: total / (len(class_counts) * count) for i, count in enumerate(class_counts)}\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=64, class_weight=class_weights, callbacks=[early_stopping])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"Run the complete pipeline to train model and generate activation maps.\"\"\"\n",
    "    df = download_dataset(n=20000)\n",
    "    X, y = prepare_data(df)\n",
    "    model = build_vgg16()\n",
    "    model = train_model(model, X, y)\n",
    "\n",
    "    model.save(\"gender_classifier_vgg.h5\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiasX pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from keras.api.applications.vgg16 import VGG16\n",
    "from keras.api.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.api.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.api.models import Model\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.regularizers import l2\n",
    "from keras.api.utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def download_dataset(n: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Download facial image dataset from HuggingFace.\"\"\"\n",
    "    filepath = hf_hub_download(repo_id=\"rixmape/utkface\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=42) if n > 0 else df\n",
    "\n",
    "\n",
    "def prepare_images(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process images to model-ready format.\"\"\"\n",
    "\n",
    "    def load_image(img_bytes):\n",
    "        with Image.open(BytesIO(img_bytes)) as image:\n",
    "            image = image.convert(\"L\").resize((48, 48))\n",
    "            image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "            return np.stack([image_array] * 3, axis=-1)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"image_array\"] = df.apply(lambda row: load_image(row[\"image\"][\"bytes\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Split data into train, validation and test sets.\"\"\"\n",
    "    images = np.stack(df[\"image_array\"].values)\n",
    "    labels = df[\"gender\"].values\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_val = to_categorical(y_val, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def build_model() -> tf.keras.Model:\n",
    "    \"\"\"Build gender classification model.\"\"\"\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Model, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray) -> tf.keras.Model:\n",
    "    \"\"\"Train model with callbacks.\"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"gender_classifier.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6),\n",
    "    ]\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=callbacks)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, X_test: np.ndarray, y_test: np.ndarray) -> dict:\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    return model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n",
    "\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"Run the complete training pipeline.\"\"\"\n",
    "    df = download_dataset()\n",
    "    df = prepare_images(df)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "\n",
    "    model = build_model()\n",
    "    model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    results = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Test accuracy: {results['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "\n",
    "RANDOM_STATE: int = 42\n",
    "N_SAMPLES: int = 1000\n",
    "IMAGE_SIZE: Tuple[int, int] = (48, 48)\n",
    "EPOCHS: int = 15\n",
    "BATCH_SIZE: int = 64\n",
    "TEST_RATIO: float = 0.2\n",
    "VAL_RATIO: float = 0.2\n",
    "\n",
    "\n",
    "def download_dataset(n: int = N_SAMPLES, repo_id: str = \"rixmape/utkface\", filename: str = \"data/train-00000-of-00001.parquet\", repo_type: str = \"dataset\") -> pd.DataFrame:\n",
    "    \"\"\"Download dataset from HuggingFace.\"\"\"\n",
    "    filepath: str = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=repo_type)\n",
    "    df: pd.DataFrame = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=RANDOM_STATE) if n > 0 else df\n",
    "\n",
    "\n",
    "def prepare_images(df: pd.DataFrame, image_size: Tuple[int, int] = IMAGE_SIZE, color_mode: str = \"L\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Prepare images and labels from a dataframe.\"\"\"\n",
    "    processed = [((np.array(Image.open(BytesIO(row[\"image\"][\"bytes\"])).convert(color_mode).resize(image_size), dtype=np.float32) / 255.0).reshape(image_size[0], image_size[1], 1), row[\"gender\"]) for _, row in df.iterrows()]\n",
    "    images, labels = zip(*processed)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def build_vgg16_model(input_shape: Tuple[int, int, int] = (IMAGE_SIZE[0], IMAGE_SIZE[1], 1)) -> tf.keras.Sequential:\n",
    "    \"\"\"Build a VGG16-like model.\"\"\"\n",
    "    model: tf.keras.Sequential = tf.keras.Sequential()\n",
    "    blocks: List[Tuple[str, int, int]] = [(\"block1\", 64, 2), (\"block2\", 128, 2), (\"block3\", 256, 3), (\"block4\", 512, 3), (\"block5\", 512, 3)]\n",
    "    for block, filters, conv_count in blocks:\n",
    "        for i in range(1, conv_count + 1):\n",
    "            kwargs = {\"filters\": filters, \"kernel_size\": (3, 3), \"activation\": \"relu\", \"padding\": \"same\", \"name\": f\"{block}_conv{i}\"}\n",
    "            if block == \"block1\" and i == 1:\n",
    "                kwargs[\"input_shape\"] = input_shape\n",
    "            model.add(tf.keras.layers.Conv2D(**kwargs))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=f\"{block}_pool\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Split dataset into training, validation, and test sets.\"\"\"\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=TEST_RATIO, random_state=RANDOM_STATE, stratify=y)\n",
    "    val_size_adjusted: float = VAL_RATIO / (1 - TEST_RATIO)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size_adjusted, random_state=RANDOM_STATE, stratify=y_temp)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Model, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray, epochs: int = EPOCHS, batch_size: int = BATCH_SIZE) -> tf.keras.Model:\n",
    "    \"\"\"Train the model using provided training and validation sets.\"\"\"\n",
    "    callbacks: List[tf.keras.callbacks.Callback] = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=1e-6),\n",
    "    ]\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=callbacks)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def generate_cam(model: tf.keras.Model, image: np.ndarray, label: int, target_layer: str = \"block3_conv3\") -> np.ndarray:\n",
    "    \"\"\"Generate Grad-CAM++ for an image.\"\"\"\n",
    "    modifier_fn = lambda m: setattr(m.layers[-1], \"activation\", tf.keras.activations.linear)\n",
    "    score_fn = lambda output: output[0][label]\n",
    "    visualizer = GradcamPlusPlus(model, model_modifier=modifier_fn, clone=True)\n",
    "    return visualizer(score_fn, image[np.newaxis, ...], penultimate_layer=target_layer)[0]\n",
    "\n",
    "\n",
    "def generate_activation_maps(model: tf.keras.Model, images: np.ndarray, labels: np.ndarray) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate activation maps for a batch of images.\"\"\"\n",
    "    return [{\"image\": np.squeeze(image), \"activation\": generate_cam(model, image, int(label)), \"label\": label} for image, label in zip(images[:32], labels[:32])]\n",
    "\n",
    "\n",
    "def display_activation_grid(results: List[Dict[str, Any]], rows: int = 4, cols: int = 8) -> None:\n",
    "    \"\"\"Display a grid of activation maps.\"\"\"\n",
    "    fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
    "    for i, result in enumerate(results[: rows * cols]):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        ax.imshow(result[\"image\"], cmap=\"gray\")\n",
    "        ax.imshow(result[\"activation\"], cmap=\"jet\", alpha=0.5)\n",
    "        ax.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"activation_maps.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"Run the complete pipeline.\"\"\"\n",
    "    df = download_dataset()\n",
    "    X, y = prepare_images(df)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X, y)\n",
    "    model = build_vgg16_model()\n",
    "    model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    maps = generate_activation_maps(model, X_train, y_train)\n",
    "    display_activation_grid(maps)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

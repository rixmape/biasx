{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from keras.api.models import load_model\n",
    "from PIL import Image\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "\n",
    "\n",
    "def initialize_model(model_path: str) -> tf.keras.Model:\n",
    "    \"\"\"Load and return the pre-trained facial classification model.\"\"\"\n",
    "    return load_model(model_path)\n",
    "\n",
    "\n",
    "def download_dataset(n: int = 32) -> pd.DataFrame:\n",
    "    \"\"\"Download and load facial image dataset from HuggingFace.\"\"\"\n",
    "    filepath = hf_hub_download(repo_id=\"rixmape/utkface\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=42) if n > 0 else df\n",
    "\n",
    "\n",
    "def process_row(row: pd.Series, model: tf.keras.Model) -> dict:\n",
    "    \"\"\"Process a single dataframe row with all pipeline steps.\"\"\"\n",
    "    with Image.open(BytesIO(row[\"image\"][\"bytes\"])) as image:\n",
    "        image = image.convert(\"L\").resize((48, 48))\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        image_array = np.stack([image_array] * 3, axis=-1)\n",
    "\n",
    "    def _modifier_fn(cloned_model: tf.keras.Model) -> None:\n",
    "        cloned_model.layers[-1].activation = tf.keras.activations.linear\n",
    "\n",
    "    def _score_fn(output: tf.Tensor) -> tf.Tensor:\n",
    "        return output[0][row[\"gender\"]]\n",
    "\n",
    "    visualizer = GradcamPlusPlus(model, model_modifier=_modifier_fn, clone=True)\n",
    "    expanded_image_array = image_array if image_array.ndim == 3 else image_array[..., np.newaxis]\n",
    "    activation = visualizer(_score_fn, expanded_image_array, penultimate_layer=-1)[0]\n",
    "\n",
    "    return {\"image\": image_array, \"activation\": activation}\n",
    "\n",
    "\n",
    "def display_results(results: list, rows: int = 4, cols: int = 8):\n",
    "    \"\"\"Display a grid of images with heatmap overlay.\"\"\"\n",
    "    n_images = rows * cols\n",
    "    sample_indices = np.random.choice(len(results), min(n_images, len(results)), replace=False)\n",
    "\n",
    "    _, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes_flat = axes.flatten()\n",
    "\n",
    "    for idx, sample_idx in enumerate(sample_indices):\n",
    "        if idx >= n_images:\n",
    "            break\n",
    "\n",
    "        result = results[sample_idx]\n",
    "        axes_flat[idx].imshow(result[\"image\"], cmap=\"gray\")\n",
    "        axes_flat[idx].imshow(result[\"activation\"], cmap=\"jet\", alpha=0.5)\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    for idx in range(len(sample_indices), len(axes_flat)):\n",
    "        axes_flat[idx].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_pipeline():\n",
    "    model = initialize_model(\"../tmp/pipeline2.keras\")\n",
    "    df = download_dataset()\n",
    "    results = df.apply(lambda row: process_row(row, model), axis=1).tolist()\n",
    "    display_results(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

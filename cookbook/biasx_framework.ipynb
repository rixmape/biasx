{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiasX: Analyzing Gender Bias in Face Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from mediapipe.tasks.python.core.base_options import BaseOptions\n",
    "from mediapipe.tasks.python.vision.face_landmarker import FaceLandmarker, FaceLandmarkerOptions\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from biasx import BiasAnalyzer\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "DATASET_NAME = \"utkface\"\n",
    "DATASET_SIZE = 5000\n",
    "DATASET_MALE_RATIO = 0.5\n",
    "DATASET_FEMALE_RATIO = 0.5\n",
    "DATASET_IMAGE_SHAPE = (96, 96, 1)\n",
    "DATASET_VALIDATION_RATIO = 0.2\n",
    "DATASET_TEST_RATIO = 0.1\n",
    "\n",
    "MASKING_TARGET_GENDER = None\n",
    "MASKING_TARGET_FEATURE = None\n",
    "MASKING_PADDING = 0\n",
    "\n",
    "MODEL_EPOCHS = 10\n",
    "MODEL_BATCH_SIZE = 32\n",
    "MODEL_DIRECTORY = \"./tmp/gender_classifier.keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Download dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset() -> pd.DataFrame:\n",
    "    \"\"\"Retrieve and load dataset from Hugging Face repository.\"\"\"\n",
    "    path = hf_hub_download(repo_id=f\"rixmape/{DATASET_NAME}\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(path, columns=[\"image\", \"gender\", \"race\", \"age\"])\n",
    "    df[\"image\"] = df[\"image\"].progress_apply(lambda x: np.array(Image.open(BytesIO(x[\"bytes\"]))))\n",
    "    return df\n",
    "\n",
    "\n",
    "dataset = load_dataset()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Sample dataset with specific gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_by_stratum(data: pd.DataFrame, total_sample_size: int) -> list:\n",
    "    \"\"\"Sample data proportionally within each stratum.\"\"\"\n",
    "    data[\"strata\"] = data[\"race\"].astype(str) + \"_\" + data[\"age\"].astype(str)\n",
    "    strat_samples = []\n",
    "\n",
    "    for _, group in data.groupby(\"strata\"):\n",
    "        group_size = len(group)\n",
    "        group_ratio = group_size / len(data)\n",
    "        stratum_sample_size = round(total_sample_size * group_ratio)\n",
    "        if stratum_sample_size > 0:\n",
    "            strat_samples.append(group.sample(n=stratum_sample_size, random_state=RANDOM_SEED, replace=(group_size < stratum_sample_size)))\n",
    "\n",
    "    return [sample.drop(columns=[\"strata\"]) for sample in strat_samples]\n",
    "\n",
    "\n",
    "def sample_with_gender_ratio(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Sample dataset with target gender ratio while balancing race and age.\"\"\"\n",
    "    gender_ratios = {0: DATASET_MALE_RATIO, 1: DATASET_FEMALE_RATIO}\n",
    "    samples = []\n",
    "\n",
    "    for gender_id, ratio in gender_ratios.items():\n",
    "        gender_sample_size = round(DATASET_SIZE * ratio)\n",
    "        gender_df = data[data[\"gender\"] == gender_id].copy(deep=True)\n",
    "        if gender_df.empty:\n",
    "            continue\n",
    "        strata_samples = _sample_by_stratum(gender_df, gender_sample_size)\n",
    "        if strata_samples:\n",
    "            samples.append(pd.concat(strata_samples))\n",
    "\n",
    "    return pd.concat(samples).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "\n",
    "dataset = sample_with_gender_ratio(dataset)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demographics(data: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Visualize distributions of gender, age, and race columns.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    columns = [\"gender\", \"age\", \"race\"]\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        sns.countplot(data=data, x=col, ax=axes[i])\n",
    "        axes[i].set_title(f\"{col.capitalize()} Distribution\")\n",
    "        axes[i].tick_params(axis=\"x\")\n",
    "        axes[i].set_ylabel(\"\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_demographics(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
    "    train_val, test = train_test_split(df, test_size=DATASET_TEST_RATIO, random_state=RANDOM_SEED, stratify=df[\"gender\"])\n",
    "    train, val = train_test_split(train_val, test_size=DATASET_VALIDATION_RATIO / (1 - DATASET_TEST_RATIO), random_state=RANDOM_SEED, stratify=train_val[\"gender\"])\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "train_set, val_set, test_set = split_dataset(dataset)\n",
    "\n",
    "# HACK: Delete `dataset` to free up memory if model training crashes\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Apply zero masking on a facial region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def _load_landmarker() -> FaceLandmarker:\n",
    "    \"\"\"Load MediaPipe facial landmark detector.\"\"\"\n",
    "    model_path = hf_hub_download(repo_id=\"rixmape/biasx-models\", filename=\"mediapipe_landmarker.task\", repo_type=\"model\")\n",
    "    options = FaceLandmarkerOptions(base_options=BaseOptions(model_asset_path=model_path))\n",
    "    return FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "def _load_landmark_map() -> dict[str, list[int]]:\n",
    "    \"\"\"Load landmark mapping based on MediaPipe documentation.\"\"\"\n",
    "    return {\n",
    "        \"left_eye\": [249, 263, 362, 373, 374, 380, 381, 382, 384, 385, 386, 387, 388, 390, 398, 466],\n",
    "        \"right_eye\": [7, 33, 133, 144, 145, 153, 154, 155, 157, 158, 159, 160, 161, 163, 173, 246],\n",
    "        \"nose\": [1, 2, 4, 5, 6, 19, 45, 48, 64, 94, 97, 98, 115, 168, 195, 197, 220, 275, 278, 294, 326, 327, 344, 440],\n",
    "        \"lips\": [0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415],\n",
    "        \"left_cheek\": [454, 447, 345, 346, 347, 330, 425, 427, 434, 416, 435, 288, 361, 323, 280, 352, 366, 411, 376, 401, 433],\n",
    "        \"right_cheek\": [234, 227, 116, 117, 118, 101, 205, 207, 214, 192, 215, 58, 132, 93, 127, 50, 123, 137, 177, 147, 187, 213],\n",
    "        \"chin\": [202, 210, 169, 150, 149, 176, 148, 152, 377, 400, 378, 379, 394, 430, 422, 211, 32, 208, 199, 428, 262, 431, 170, 140, 171, 175, 396, 369, 395],\n",
    "        \"forehead\": [54, 71, 68, 104, 69, 109, 151, 337, 299, 333, 298, 301, 284, 332, 297, 338, 10, 67, 103],\n",
    "        \"left_eyebrow\": [276, 282, 283, 285, 293, 295, 296, 300, 334, 336],\n",
    "        \"right_eyebrow\": [46, 52, 53, 55, 63, 65, 66, 70, 105, 107],\n",
    "    }\n",
    "\n",
    "\n",
    "def _detect_landmarks(image: np.ndarray, landmarker: FaceLandmarker) -> list:\n",
    "    \"\"\"Detect facial landmarks using MediaPipe directly from NumPy array.\"\"\"\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "    result = landmarker.detect(mp_image)\n",
    "    return result.face_landmarks[0] if result.face_landmarks else None\n",
    "\n",
    "\n",
    "def _normalize_landmarks(landmarks: list, image_size: tuple[int, int]) -> list[tuple[int, int]]:\n",
    "    \"\"\"Convert normalized landmark coordinates to pixel values.\"\"\"\n",
    "    height, width = image_size[:2]\n",
    "    return [(int(point.x * width), int(point.y * height)) for point in landmarks]\n",
    "\n",
    "\n",
    "def _get_feature_box(landmarks: list[tuple[int, int]], landmark_map: dict[str, list[int]]) -> tuple[int, int, int, int]:\n",
    "    \"\"\"Calculate the bounding box for a facial feature.\"\"\"\n",
    "    feature_points = [landmarks[i] for i in landmark_map[MASKING_TARGET_FEATURE]]\n",
    "    min_x = max(0, min(x for x, _ in feature_points) - MASKING_PADDING)\n",
    "    min_y = max(0, min(y for _, y in feature_points) - MASKING_PADDING)\n",
    "    max_x = max(x for x, _ in feature_points) + MASKING_PADDING\n",
    "    max_y = max(y for _, y in feature_points) + MASKING_PADDING\n",
    "    return (int(min_x), int(min_y), int(max_x), int(max_y))\n",
    "\n",
    "\n",
    "def _apply_zero_mask(image: np.ndarray, landmarker: FaceLandmarker, landmark_map: dict[str, list[int]]) -> np.ndarray:\n",
    "    \"\"\"Apply zero masking to a specific facial feature directly using NumPy operations.\"\"\"\n",
    "    landmarks = _detect_landmarks(image, landmarker)\n",
    "    if not landmarks:\n",
    "        return image\n",
    "    pixel_landmarks = _normalize_landmarks(landmarks, image.shape)\n",
    "    result = image.copy()\n",
    "    min_x, min_y, max_x, max_y = _get_feature_box(pixel_landmarks, landmark_map)\n",
    "    result[min_y:max_y, min_x:max_x] = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "def apply_feature_masking(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Apply zero masking to a specific facial feature for targeted gender.\"\"\"\n",
    "    if MASKING_TARGET_GENDER is None or MASKING_TARGET_FEATURE is None:\n",
    "        return data\n",
    "\n",
    "    landmarker = _load_landmarker()\n",
    "    landmark_map = _load_landmark_map()\n",
    "\n",
    "    result = data.copy()\n",
    "    gender_mask = result[\"gender\"] == MASKING_TARGET_GENDER\n",
    "    result.loc[gender_mask, \"image\"] = result.loc[gender_mask, \"image\"].progress_apply(lambda img: _apply_zero_mask(img, landmarker, landmark_map))\n",
    "    return result\n",
    "\n",
    "\n",
    "train_set = apply_feature_masking(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(data: pd.DataFrame, rows: int = 4, cols: int = 16, title: str = None) -> plt.Figure:\n",
    "    \"\"\"Visualize images from dataframe in a grid layout.\"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows))\n",
    "    axes = axes.flatten()\n",
    "    cmap = \"gray\" if data.iloc[0][\"image\"].shape[2] == 1 else None\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(data):\n",
    "            ax.imshow(np.array(data.iloc[i][\"image\"]), cmap=cmap)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_image_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Preprocess image for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Preprocess a single image.\"\"\"\n",
    "    image_array = np.array(Image.fromarray(image).convert(\"L\").resize(DATASET_IMAGE_SHAPE[:2]))\n",
    "    return (image_array / 255.0).reshape(DATASET_IMAGE_SHAPE)\n",
    "\n",
    "\n",
    "def prepare_dataset(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess all images in dataset for model input.\"\"\"\n",
    "    processed = data.copy()\n",
    "    processed[\"image\"] = processed[\"image\"].apply(_preprocess_image)\n",
    "    return processed\n",
    "\n",
    "\n",
    "train_set = prepare_dataset(train_set)\n",
    "val_set = prepare_dataset(val_set)\n",
    "test_set = prepare_dataset(test_set)\n",
    "\n",
    "fig = plot_image_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Build model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    \"\"\"Create and compile gender classification model.\"\"\"\n",
    "    model = tf.keras.Sequential(name=\"gender_classifier\")\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\", input_shape=DATASET_IMAGE_SHAPE))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block1_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block2_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block3_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten(name=\"flatten\"))\n",
    "    model.add(tf.keras.layers.Dense(512, activation=\"relu\", name=\"dense_1\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5, name=\"dropout\"))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\", name=\"dense_output\"))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract features and labels from dataframe.\"\"\"\n",
    "    features = np.stack(df[\"image\"].values)\n",
    "    labels = df[\"gender\"].values\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Model, train_df: pd.DataFrame, val_df: pd.DataFrame) -> dict[str, list[float]]:\n",
    "    \"\"\"Train model and return history.\"\"\"\n",
    "    train_data, train_labels = extract_data(train_df)\n",
    "    val_data, val_labels = extract_data(val_df)\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2),\n",
    "        tf.keras.callbacks.ModelCheckpoint(MODEL_DIRECTORY, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, verbose=1),\n",
    "    ]\n",
    "    history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), batch_size=MODEL_BATCH_SIZE, epochs=MODEL_EPOCHS, callbacks=callbacks, verbose=1, shuffle=True)\n",
    "    return history.history\n",
    "\n",
    "\n",
    "history = train_model(model, train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: tf.keras.Model, test_df: pd.DataFrame) -> dict[str, float]:\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    test_data, test_labels = extract_data(test_df)\n",
    "    loss, accuracy = model.evaluate(test_data, test_labels, batch_size=MODEL_BATCH_SIZE, verbose=0)\n",
    "    return {\"loss\": loss, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "evaluation_data = evaluate_model(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_evaluation(history: dict[str, list[float]], eval_data: dict[str, float]) -> plt.Figure:\n",
    "    \"\"\"Visualize model training history with final evaluation metrics.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    hist_data = pd.DataFrame(history)\n",
    "    epochs = len(hist_data)\n",
    "\n",
    "    sns.lineplot(data=hist_data[[\"accuracy\", \"val_accuracy\"]], ax=axes[0], dashes=[(None, None), (2, 2)])\n",
    "    axes[0].plot(epochs, eval_data[\"accuracy\"], \"ro\", markersize=8, label=\"Evaluation\")\n",
    "    axes[0].set_title(\"Model Accuracy\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Accuracy\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    sns.lineplot(data=hist_data[[\"loss\", \"val_loss\"]], ax=axes[1], dashes=[(None, None), (2, 2)])\n",
    "    axes[1].plot(epochs, eval_data[\"loss\"], \"ro\", markersize=8, label=\"Evaluation\")\n",
    "    axes[1].set_title(\"Model Loss\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_history_evaluation(history, evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"path\": MODEL_DIRECTORY,\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"source\": \"utkface\",\n",
    "        \"image_width\": DATASET_IMAGE_SHAPE[1],\n",
    "        \"image_height\": DATASET_IMAGE_SHAPE[0],\n",
    "        \"max_samples\": 500,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "result = BiasAnalyzer(config).analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_disparity_scores(analysis_result):\n",
    "    \"\"\"Visualize bias disparity scores from analysis result.\"\"\"\n",
    "    disparity_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Metric\": [\"BiasX Score\", \"Equalized Odds\"],\n",
    "            \"Value\": [\n",
    "                analysis_result.disparity_scores.biasx,\n",
    "                analysis_result.disparity_scores.equalized_odds,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.barplot(x=\"Metric\", y=\"Value\", data=disparity_df, palette=\"Blues_d\", ax=ax)\n",
    "    ax.set_title(\"Bias Scores\")\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = visualize_disparity_scores(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_probabilities(analysis_result):\n",
    "    \"\"\"Visualize gender probability distribution by feature.\"\"\"\n",
    "    data = [\n",
    "        {\n",
    "            \"Feature\": feature.value,\n",
    "            \"Male Probability\": analysis.male_probability,\n",
    "            \"Female Probability\": analysis.female_probability,\n",
    "            \"Bias Score\": analysis.bias_score,\n",
    "        }\n",
    "        for feature, analysis in analysis_result.feature_analyses.items()\n",
    "    ]\n",
    "    feature_df = pd.DataFrame(data)\n",
    "\n",
    "    melted_df = pd.melt(\n",
    "        feature_df,\n",
    "        id_vars=[\"Feature\"],\n",
    "        value_vars=[\"Male Probability\", \"Female Probability\"],\n",
    "        var_name=\"Gender\",\n",
    "        value_name=\"Probability\"\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    sns.barplot(x=\"Feature\", y=\"Probability\", hue=\"Gender\", data=melted_df, ax=ax)\n",
    "\n",
    "    for i, row in feature_df.iterrows():\n",
    "        top_val = max(row[\"Male Probability\"], row[\"Female Probability\"])\n",
    "        ax.text(i, top_val + 0.03, f\"B: {row['Bias Score']:.3f}\", ha=\"center\")\n",
    "\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title(\"Feature Probabilities by Gender\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = visualize_feature_probabilities(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

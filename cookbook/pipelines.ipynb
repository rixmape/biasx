{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identiface pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def download_dataset(n: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Download facial image dataset from HuggingFace.\"\"\"\n",
    "    filepath = hf_hub_download(repo_id=\"rixmape/utkface\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=42) if n > 0 else df\n",
    "\n",
    "\n",
    "def prepare_data(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Process images and prepare training data.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        with Image.open(BytesIO(row[\"image\"][\"bytes\"])) as img:\n",
    "            img = img.convert(\"L\").resize((48, 48))\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "            img_array = img_array.reshape(48, 48, 1)\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(row[\"gender\"])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def build_vgg16() -> tf.keras.Sequential:\n",
    "    \"\"\"Build VGG16-like architecture using Sequential API.\"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(48, 48, 1), name=\"block1_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block1_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block2_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block3_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block4_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\"))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block5_pool\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Sequential, X: np.ndarray, y: np.ndarray) -> tf.keras.Sequential:\n",
    "    \"\"\"Train model with class balancing and early stopping.\"\"\"\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total = len(y_train)\n",
    "    class_weights = {i: total / (len(class_counts) * count) for i, count in enumerate(class_counts)}\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=64, class_weight=class_weights, callbacks=[early_stopping])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"Run the complete pipeline to train model and generate activation maps.\"\"\"\n",
    "    df = download_dataset(n=20000)\n",
    "    X, y = prepare_data(df)\n",
    "    model = build_vgg16()\n",
    "    model = train_model(model, X, y)\n",
    "\n",
    "    model.save(\"gender_classifier_vgg.h5\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiasX pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from keras.api.applications.vgg16 import VGG16\n",
    "from keras.api.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.api.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.api.models import Model\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.regularizers import l2\n",
    "from keras.api.utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def download_dataset(n: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Download facial image dataset from HuggingFace.\"\"\"\n",
    "    filepath = hf_hub_download(repo_id=\"rixmape/utkface\", filename=\"data/train-00000-of-00001.parquet\", repo_type=\"dataset\")\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df.sample(n=n, random_state=42) if n > 0 else df\n",
    "\n",
    "\n",
    "def prepare_images(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process images to model-ready format.\"\"\"\n",
    "\n",
    "    def load_image(img_bytes):\n",
    "        with Image.open(BytesIO(img_bytes)) as image:\n",
    "            image = image.convert(\"L\").resize((48, 48))\n",
    "            image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "            return np.stack([image_array] * 3, axis=-1)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"image_array\"] = df.apply(lambda row: load_image(row[\"image\"][\"bytes\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Split data into train, validation and test sets.\"\"\"\n",
    "    images = np.stack(df[\"image_array\"].values)\n",
    "    labels = df[\"gender\"].values\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_val = to_categorical(y_val, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def build_model() -> tf.keras.Model:\n",
    "    \"\"\"Build gender classification model.\"\"\"\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model: tf.keras.Model, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray) -> tf.keras.Model:\n",
    "    \"\"\"Train model with callbacks.\"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"gender_classifier.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6),\n",
    "    ]\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=callbacks)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, X_test: np.ndarray, y_test: np.ndarray) -> dict:\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    return model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n",
    "\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"Run the complete training pipeline.\"\"\"\n",
    "    df = download_dataset()\n",
    "    df = prepare_images(df)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "\n",
    "    model = build_model()\n",
    "    model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    results = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Test accuracy: {results['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
